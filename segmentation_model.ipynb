{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segmentation_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1I61kYxdeY_e-y7_7sNtBKbCVJMvoqLJ0",
      "authorship_tag": "ABX9TyNcUUD3E3yPvkt/hq78aTa7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/hairy_gan/blob/master/segmentation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmArMn_FGXpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "project_path = '/content/drive/My Drive/hairy_gan/'\n",
        "dataset_path = os.path.join(project_path, 'face_segment')\n",
        "src_img_target_path = os.path.join(dataset_path, 'trainI')\n",
        "label_img_target_path = os.path.join(dataset_path, 'trainS_original')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgpjCF0Fe4qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from glob import glob\n",
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "\n",
        "# project_path = '/content/drive/My Drive/hairy_gan'\n",
        "# files = glob(os.path.join(project_path, 'face_segment', 'trainS_original', '*.jpg'))\n",
        "# target_folder = os.path.join(project_path, 'face_segment', 'trainS')\n",
        "# if not os.path.exists(target_folder):\n",
        "#   os.makedirs(target_folder)\n",
        "\n",
        "# for f in files:\n",
        "#   img = cv2.imread(f)\n",
        "#   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#   target_img = np.where(img == (255, 255, 0), 255, 0)[:, :, 0]\n",
        "#   # print(f'{f} vs {os.path.join(target_folder, os.path.basename(f))}')\n",
        "#   cv2.imwrite(os.path.join(target_folder, os.path.basename(f)), target_img)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkczVm_WBHyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # move images and corresponding segmentation masks into their own folders\n",
        "# if not os.path.exists(src_img_target_path):\n",
        "#   os.makedirs(src_img_target_path)\n",
        "\n",
        "# if not os.path.exists(label_img_target_path):\n",
        "#   os.makedirs(label_img_target_path)\n",
        "  \n",
        "# tree = ET.parse(os.path.join(dataset_path, 'sampleset.xml'))\n",
        "# root = tree.getroot()\n",
        "# children = root.getchildren()\n",
        "# for i in range(len(children) // 2):\n",
        "#   src_img_path = children[2 * i].get('name').replace('\\\\', '/')\n",
        "#   label_img_path = children[2 * i + 1].get('name').replace('\\\\', '/')\n",
        "  \n",
        "#   shutil.copy(os.path.join(dataset_path, src_img_path), os.path.join(src_img_target_path, os.path.basename(src_img_path)))\n",
        "#   shutil.copy(os.path.join(dataset_path, label_img_path), os.path.join(label_img_target_path, os.path.basename(label_img_path)))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2WmmlCzDYKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "42780196-e28c-45ec-8ba7-c9d5e5f8ee2c"
      },
      "source": [
        "!git clone https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && cd keras-contrib \\\n",
        "    && pip install git+https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && python convert_to_tf_keras.py \\\n",
        "    && USE_TF_KERAS=1 python setup.py install\n",
        "\n",
        "!pip install pillow\n",
        "!pip install scipy==1.1.0        "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'keras-contrib' already exists and is not an empty directory.\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QsonbJdyaye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8a8349b7-ca51-433c-b1d9-7f26f5d90946"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import PIL\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_v2_behavior()\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqcAQNxPGMQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, dataset_path, img_res=(128, 128)):\n",
        "      self.dataset_path = dataset_path\n",
        "      self.img_res = img_res\n",
        "\n",
        "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
        "      # data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
        "      data_type = 'train' + domain # always grab from training since we have no test\n",
        "      path = glob(os.path.join(self.dataset_path, data_type, '*'))\n",
        "\n",
        "      batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "      imgs = []\n",
        "      for img_path in batch_images:\n",
        "          img = self.imread(img_path)\n",
        "          if not is_testing:\n",
        "              img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "              if np.random.random() > 0.5:\n",
        "                  img = np.fliplr(img)\n",
        "          else:\n",
        "              img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "          if domain == 'S':\n",
        "            # super inefficient to this last but...\n",
        "            img = np.expand_dims(img[:, :, 0], axis=-1)\n",
        "\n",
        "          imgs.append(img)\n",
        "\n",
        "      imgs = np.array(imgs)\n",
        "      imgs = imgs /127.5 - 1.\n",
        "\n",
        "      return imgs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "      data_type = \"train\" if not is_testing else \"val\"\n",
        "\n",
        "      folder_1 = os.path.join(self.dataset_path, data_type + 'I')\n",
        "      folder_2 = os.path.join(self.dataset_path, data_type + 'S')\n",
        "      path_I = glob(os.path.join(folder_1, '*'))\n",
        "      path_S = glob(os.path.join(folder_2, '*'))\n",
        "\n",
        "      self.n_batches = int(min(len(path_I), len(path_S)) / batch_size)\n",
        "      total_samples = self.n_batches * batch_size\n",
        "\n",
        "      # Sample n_batches * batch_size from each path list so that model sees all\n",
        "      # samples from both domains\n",
        "      path_I = np.random.choice(path_I, total_samples, replace=False)\n",
        "      path_S = np.array([glob(os.path.join(os.path.dirname(path), '../', 'trainS', '*'))[0] for path in path_I])\n",
        "      # path_S = np.random.choice(path_S, total_samples, replace=False)\n",
        "\n",
        "      i = 0\n",
        "      while True:\n",
        "          batch_I = path_I[i*batch_size:(i+1)*batch_size]\n",
        "          batch_S = path_S[i*batch_size:(i+1)*batch_size]\n",
        "          imgs_I, imgs_S = [], []\n",
        "          for img_I, img_S in zip(batch_I, batch_S):\n",
        "              img_I = self.imread(img_I)\n",
        "              img_S = self.imread(img_S)\n",
        "\n",
        "              img_I = scipy.misc.imresize(img_I, self.img_res)\n",
        "              img_S = scipy.misc.imresize(img_S, self.img_res)\n",
        "\n",
        "              if not is_testing and np.random.random() > 0.5:\n",
        "                      img_I = np.fliplr(img_I)\n",
        "                      img_S = np.fliplr(img_S)\n",
        "\n",
        "              # super inefficient to this last but...\n",
        "              img_S = np.expand_dims(img_S[:, :, 0], axis=-1)\n",
        "\n",
        "              imgs_I.append(img_I)\n",
        "              imgs_S.append(img_S)\n",
        "\n",
        "          imgs_I = np.array(imgs_I)/127.5 - 1.\n",
        "          imgs_S = np.array(imgs_S) / 255.\n",
        "          \n",
        "          i += 1\n",
        "\n",
        "          if i == self.n_batches - 1:\n",
        "            path_I = np.random.choice(path_I, total_samples, replace=False)\n",
        "            path_S = np.array([glob(os.path.join(os.path.dirname(path), '../', 'trainS', '*'))[0] for path in path_I])\n",
        "            # path_S = np.random.choice(path_S, total_samples, replace=False)\n",
        "            i = 0\n",
        "          yield imgs_I, imgs_S\n",
        "\n",
        "    def imread(self, path):\n",
        "      return scipy.misc.imread(path, mode='RGB').astype(np.float)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7awGdclIMOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SegGAN():\n",
        "  def __init__(self):\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.img_channels = 3\n",
        "\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
        "\n",
        "    self.data_loader = DataLoader(dataset_path, img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "    # patch = int(self.img_rows / 2**4)\n",
        "    # self.disc_patch = (patch, patch, 1) # output shape of discriminator\n",
        "    self.segment_shape = self.img_shape[:-1] + (1,)\n",
        "\n",
        "    self.gf = 32 # num filters in first layer of gen\n",
        "    self.df = 64 # num filters in first layer of disc\n",
        "\n",
        "    optimizer = Adam(0.0002, 0.5, 0.999)\n",
        "\n",
        "    self.d_I = self.build_discriminator()\n",
        "    self.d_S = self.build_discriminator(segment=True)\n",
        "\n",
        "    self.d_I.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "    self.d_S.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    self.d_I_output_shape = tuple(self.d_I.layers[-1].output.get_shape().as_list()[1:])\n",
        "    self.d_S_output_shape = tuple(self.d_S.layers[-1].output.get_shape().as_list()[1:])\n",
        "\n",
        "    self.g_IS = self.build_generator(segment=True)\n",
        "    self.g_SI = self.build_generator()\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'd_I.weights')):\n",
        "      self.d_I.load_weights(os.path.join(project_path, 'd_I.weights'))\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'd_S.weights')):\n",
        "      self.d_S.load_weights(os.path.join(project_path, 'd_S.weights'))\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'g_IS.weights')):\n",
        "      self.g_IS.load_weights(os.path.join(project_path, 'g_IS.weights'))\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'g_SI.weights')):\n",
        "      self.g_SI.load_weights(os.path.join(project_path, 'g_SI.weights'))\n",
        "\n",
        "    img_I = Input(shape=self.img_shape)\n",
        "    img_S = Input(shape=self.segment_shape)\n",
        "\n",
        "    fake_S = self.g_IS(img_I)\n",
        "    fake_I = self.g_SI(img_S)\n",
        "\n",
        "    reconstr_I = self.g_SI(fake_S)\n",
        "    reconstr_S = self.g_IS(fake_I)\n",
        "\n",
        "    valid_I = self.d_I(fake_I)\n",
        "    valid_S = self.d_S(fake_S)\n",
        "\n",
        "    self.combined = Model(inputs=[img_I, img_S], outputs=[valid_I, valid_S, fake_S, fake_I, reconstr_I, reconstr_S])\n",
        "    self.combined.compile(loss=['mse', 'mse', 'binary_crossentropy', 'mse', 'mae', 'binary_crossentropy'], loss_weights=[1, 1, 1, 1, 1, 0.05], optimizer=optimizer)\n",
        "\n",
        "  def build_generator(self, segment=False):\n",
        "    '''U-net generator'''\n",
        "\n",
        "    def conv2d(layer_input, filters, f_size=4):\n",
        "      '''Layers used during downsampling'''\n",
        "      d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "      d = LeakyReLU(alpha=0.2)(d)\n",
        "      d = InstanceNormalization()(d)\n",
        "      return d\n",
        "\n",
        "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
        "      '''Layers used during upsampling'''\n",
        "      u = UpSampling2D(size=2)(layer_input)\n",
        "      u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
        "\n",
        "      if dropout_rate:\n",
        "        u = Dropout(dropout_rate)(u)\n",
        "      u = InstanceNormalization()(u)\n",
        "      u = Concatenate()([u, skip_input])\n",
        "      return u\n",
        "\n",
        "    if segment:\n",
        "      d0 = Input(shape=self.img_shape)\n",
        "    else:\n",
        "      d0 = Input(shape=self.segment_shape)\n",
        "    d1 = conv2d(d0, self.gf)\n",
        "    d2 = conv2d(d1, self.gf * 2)\n",
        "    d3 = conv2d(d2, self.gf * 4)\n",
        "    d4 = conv2d(d3, self.gf * 8)\n",
        "\n",
        "    u1 = deconv2d(d4, d3, self.gf * 4)\n",
        "    u2 = deconv2d(u1, d2, self.gf * 2)\n",
        "    u3 = deconv2d(u2, d1, self.gf)\n",
        "\n",
        "    u4 = UpSampling2D(size=2)(u3)\n",
        "\n",
        "    if not segment:\n",
        "      output_img = Conv2D(self.img_channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
        "    else:\n",
        "      output_img = Conv2D(1, kernel_size=4, strides=1, padding='same', activation='sigmoid')(u4)\n",
        "\n",
        "    return Model(d0, output_img)\n",
        "\n",
        "  def build_discriminator(self, segment=False):\n",
        "  \n",
        "    if not segment:\n",
        "      input = Input(shape=self.img_shape)\n",
        "    else:\n",
        "      input = Input(shape=self.segment_shape)\n",
        "    d1 = Conv2D(self.df, kernel_size=1, strides=1, padding='same')(input)\n",
        "    d2 = LeakyReLU(alpha=0.2)(d1)\n",
        "    d3 = Conv2D(self.df * 2, kernel_size=1, strides=1, padding='same')(d2)\n",
        "    d4 = BatchNormalization()(d3)\n",
        "    d5 = LeakyReLU(alpha=0.2)(d4)\n",
        "    d6 = Conv2D(self.df * 2, kernel_size=1, strides=1, padding='same', activation='sigmoid')(d5)\n",
        "\n",
        "    return Model(input, d6)\n",
        "\n",
        "  def train(self, epochs, batch_size=1, sample_interval=50):\n",
        "    start_time = datetime.datetime.now()\n",
        "\n",
        "    valid_I = np.ones((batch_size, ) + self.d_I_output_shape)\n",
        "    fake_gen_I = np.zeros((batch_size, ) + self.d_I_output_shape)\n",
        "\n",
        "    valid_S = np.ones((batch_size, ) + self.d_S_output_shape)\n",
        "    fake_gen_S = np.zeros((batch_size, ) + self.d_S_output_shape)\n",
        "\n",
        "    batch_gen = self.data_loader.load_batch(batch_size)\n",
        "    for i, elem in enumerate(batch_gen):\n",
        "      break\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      steps_per_epoch = self.data_loader.n_batches\n",
        "      for batch_i in tqdm(range(steps_per_epoch), desc=f'Train {epoch} / {epochs}', total=steps_per_epoch):\n",
        "        imgs_I, imgs_S = next(batch_gen)\n",
        "        fake_S = self.g_IS.predict(imgs_I)\n",
        "        fake_I = self.g_SI.predict(imgs_S)\n",
        "\n",
        "        dI_loss_real = self.d_I.fit(imgs_I, valid_I)\n",
        "        dI_loss_fake = self.d_I.fit(fake_I, fake_gen_I)\n",
        "\n",
        "        # dI_loss = 0.5 * np.add(dI_loss_real, dI_loss_fake)\n",
        "\n",
        "        dS_loss_real = self.d_S.fit(imgs_S, valid_S)\n",
        "        dS_loss_fake = self.d_S.fit(fake_S, fake_gen_S)\n",
        "\n",
        "        # dS_loss = 0.5 * np.add(dS_loss_real, dS_loss_fake)\n",
        "\n",
        "        # d_loss = 0.5 * np.add(dI_loss, dS_loss)\n",
        "\n",
        "        g_loss = self.combined.fit([imgs_I, imgs_S], [fake_gen_I, fake_gen_S, imgs_S, imgs_I, imgs_I, imgs_S])\n",
        "\n",
        "        if batch_i % sample_interval == 0:\n",
        "          self.sample_images(epoch, batch_i)\n",
        "\n",
        "          # save weights (cannot save model because eager behavior disabled)\n",
        "          self.d_I.save_weights('d_I.weights')\n",
        "          shutil.copy('d_I.weights', os.path.join(project_path, 'd_I.weights'))\n",
        "\n",
        "          self.d_S.save_weights('d_S.weights')\n",
        "          shutil.copy('d_S.weights', os.path.join(project_path, 'd_S.weights'))\n",
        "\n",
        "          self.g_IS.save_weights('g_IS.weights')\n",
        "          shutil.copy('g_IS.weights', os.path.join(project_path, 'g_IS.weights'))\n",
        "\n",
        "          self.g_SI.save_weights('g_SI.weights')\n",
        "          shutil.copy('g_SI.weights', os.path.join(project_path, 'g_SI.weights'))\n",
        "  \n",
        "  def sample_images(self, epoch, batch_i):\n",
        "    format_size = 20\n",
        "    print('=' * format_size)\n",
        "\n",
        "    r, c = 2, 3\n",
        "\n",
        "    imgs_I = self.data_loader.load_data(domain=\"I\", batch_size=1, is_testing=True)\n",
        "    imgs_S = self.data_loader.load_data(domain=\"S\", batch_size=1, is_testing=True)\n",
        "    \n",
        "    # Translate images to the other domain\n",
        "    fake_S = self.g_IS.predict(imgs_I)\n",
        "    fake_I = self.g_SI.predict(imgs_S)\n",
        "    # Translate back to original domain\n",
        "    reconstr_I = self.g_SI.predict(fake_S)\n",
        "    reconstr_S = self.g_IS.predict(fake_I)\n",
        "\n",
        "    # super inefficient but works..\n",
        "    imgs_S = self.batch_gray_to_rgb(self.post_process(imgs_S))\n",
        "    fake_S = self.batch_gray_to_rgb(self.post_process(fake_S))\n",
        "    reconstr_S = self.batch_gray_to_rgb(self.post_process(reconstr_S))\n",
        "\n",
        "    gen_imgs = np.concatenate([imgs_I, fake_S, reconstr_I, imgs_S, fake_I, reconstr_S])\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    titles = ['Original', 'Translated', 'Reconstructed']\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt])\n",
        "            axs[i, j].set_title(titles[j])\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    plt.show()\n",
        "\n",
        "    print('=' * format_size)\n",
        "\n",
        "  def post_process(self, batch):\n",
        "    return (batch + 1.) * 127.5\n",
        "\n",
        "  def batch_gray_to_rgb(self, batch):\n",
        "    return np.array([cv2.cvtColor(np.squeeze(img).astype(np.uint8), cv2.COLOR_GRAY2RGB) for img in batch])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af6YDDpkJNmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d1f4a3a0-90d7-456f-dad3-65be2e0be146"
      },
      "source": [
        "gan = SegGAN()\n",
        "gan.train(epochs=10000, batch_size=5, sample_interval=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "\n",
            "\n",
            "\n",
            "Train 0 / 10000:   0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "5/5 [==============================] - 1s 211ms/step - loss: 0.2636 - accuracy: 0.0000e+00\n",
            "Epoch 1/1\n",
            "5/5 [==============================] - 1s 124ms/step - loss: 0.1491 - accuracy: 0.0037\n",
            "Epoch 1/1\n",
            "5/5 [==============================] - 1s 207ms/step - loss: 0.2304 - accuracy: 0.8602\n",
            "Epoch 1/1\n",
            "5/5 [==============================] - 1s 122ms/step - loss: 0.0316 - accuracy: 0.0000e+00\n",
            "Epoch 1/1\n",
            "5/5 [==============================] - 8s 2s/step - loss: 19.9493 - model_45_loss: 0.1474 - model_46_loss: 0.0316 - model_47_loss: 5.0257 - model_48_loss: 0.6244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C85Yf-X1ueP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_gen = gan.data_loader.load_batch(1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIn-7Thz2DYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "43dadd1e-eb05-459c-c769-95eb47a36715"
      },
      "source": [
        "imgs_I, imgs_S = next(batch_gen)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/hairy_gan/face_segment/trainI/../trainS/headrende0000.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kZrbKLWkzxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "bbd08a41-5b17-49ae-b24a-e2e84d10a118"
      },
      "source": [
        "gan.g_IS.predict(imgs_I)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[1.8699233e-36],\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         ...,\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         [5.6884834e-26]],\n",
              "\n",
              "        [[0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         ...,\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         [1.0831667e-35]],\n",
              "\n",
              "        [[0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         ...,\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         [2.9718603e-37]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         ...,\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         [3.3083758e-37]],\n",
              "\n",
              "        [[0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         ...,\n",
              "         [0.0000000e+00],\n",
              "         [0.0000000e+00],\n",
              "         [1.3073414e-27]],\n",
              "\n",
              "        [[5.5859268e-28],\n",
              "         [9.3720865e-38],\n",
              "         [0.0000000e+00],\n",
              "         ...,\n",
              "         [1.8376493e-36],\n",
              "         [2.5702371e-27],\n",
              "         [7.0713627e-18]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8yq26ekk08T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}