{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segmentation_model.ipynb",
      "provenance": [],
      "mount_file_id": "1I61kYxdeY_e-y7_7sNtBKbCVJMvoqLJ0",
      "authorship_tag": "ABX9TyPEfTa9gm9H9oTlLjlj7G5Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/hairy_gan/blob/master/segmentation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmArMn_FGXpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "project_path = '/content/drive/My Drive/hairy_gan/'\n",
        "dataset_path = os.path.join(project_path, 'face_segment')\n",
        "src_img_target_path = os.path.join(dataset_path, 'trainA')\n",
        "label_img_target_path = os.path.join(dataset_path, 'trainB')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkczVm_WBHyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# move images and corresponding segmentation masks into their own folders\n",
        "# tree = ET.parse(os.path.join(dataset_path, 'sampleset.xml'))\n",
        "# root = tree.getroot()\n",
        "# children = root.getchildren()\n",
        "# for i in range(len(children) // 2):\n",
        "#   src_img_path = children[2 * i].get('name').replace('\\\\', '/')\n",
        "#   label_img_path = children[2 * i + 1].get('name').replace('\\\\', '/')\n",
        "  \n",
        "#   shutil.copy(os.path.join(dataset_path, src_img_path), os.path.join(src_img_target_path, os.path.basename(src_img_path)))\n",
        "#   shutil.copy(os.path.join(dataset_path, label_img_path), os.path.join(label_img_target_path, os.path.basename(label_img_path)))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2WmmlCzDYKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "5aad1eff-ea8c-4364-c990-9312d89f7a26"
      },
      "source": [
        "!git clone https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && cd keras-contrib \\\n",
        "    && pip install git+https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && python convert_to_tf_keras.py \\\n",
        "    && USE_TF_KERAS=1 python setup.py install\n",
        "\n",
        "!pip install pillow\n",
        "!pip install scipy==1.1.0        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-contrib'...\n",
            "warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n",
            "remote: Enumerating objects: 3634, done.\u001b[K\n",
            "remote: Total 3634 (delta 0), reused 0 (delta 0), pack-reused 3634\u001b[K\n",
            "Receiving objects: 100% (3634/3634), 861.24 KiB | 7.69 MiB/s, done.\n",
            "Resolving deltas: 100% (2330/2330), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QsonbJdyaye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import PIL\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqcAQNxPGMQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, dataset_path, img_res=(128, 128)):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.img_res = img_res\n",
        "\n",
        "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
        "        # data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
        "        data_type = 'train' + domain # always grab from training since we have no test\n",
        "        path = glob(os.path.join(self.dataset_path, data_type, '*'))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs = []\n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "\n",
        "        return imgs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"val\"\n",
        "        path_A = glob(os.path.join(self.dataset_path, data_type + 'A', '*'))\n",
        "        path_B = glob(os.path.join(self.dataset_path, data_type + 'B', '*'))\n",
        "\n",
        "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        # Sample n_batches * batch_size from each path list so that model sees all\n",
        "        # samples from both domains\n",
        "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
        "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
        "\n",
        "        i = 0\n",
        "        while True:\n",
        "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
        "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
        "            imgs_A, imgs_B = [], []\n",
        "            for img_A, img_B in zip(batch_A, batch_B):\n",
        "                img_A = self.imread(img_A)\n",
        "                img_B = self.imread(img_B)\n",
        "\n",
        "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
        "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img_A = np.fliplr(img_A)\n",
        "                        img_B = np.fliplr(img_B)\n",
        "\n",
        "                imgs_A.append(img_A)\n",
        "                imgs_B.append(img_B)\n",
        "\n",
        "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "            i += 1\n",
        "\n",
        "            if i == self.n_batches - 1:\n",
        "              path_A = np.random.choice(path_A, total_samples, replace=False)\n",
        "              path_B = np.random.choice(path_B, total_samples, replace=False)\n",
        "              i = 0\n",
        "            yield imgs_A, imgs_B\n",
        "\n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode='RGB').astype(np.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7awGdclIMOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CycleGAN():\n",
        "  def __init__(self):\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.img_channels = 3\n",
        "\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
        "\n",
        "    self.data_loader = DataLoader(dataset_path, img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "    patch = int(self.img_rows / 2**4)\n",
        "    self.disc_patch = (patch, patch, 1) # output shape of discriminator\n",
        "\n",
        "    self.gf = 32 # num filters in first layer of gen\n",
        "    self.df = 64 # num filters in first layer of disc\n",
        "\n",
        "    self.lambda_cycle = 10.0\n",
        "    self.lambda_id = 0.9 * self.lambda_cycle # identity loss weight\n",
        "\n",
        "    optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "    self.d_A = self.build_discriminator()\n",
        "    self.d_B = self.build_discriminator()\n",
        "\n",
        "    self.d_A.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "    self.d_B.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    self.g_AB = self.build_generator()\n",
        "    self.g_BA = self.build_generator()\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'd_A.weights')):\n",
        "      self.d_A.load_weights(os.path.join(project_path, 'd_A.weights'))\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'd_B.weights')):\n",
        "      self.d_B.load_weights(os.path.join(project_path, 'd_B.weights'))\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'g_AB.weights')):\n",
        "      self.g_AB.load_weights(os.path.join(project_path, 'g_AB.weights'))\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'g_BA.weights')):\n",
        "      self.g_BA.load_weights(os.path.join(project_path, 'g_BA.weights'))\n",
        "\n",
        "    img_A = Input(shape=self.img_shape)\n",
        "    img_B = Input(shape=self.img_shape)\n",
        "\n",
        "    fake_B = self.g_AB(img_A)\n",
        "    fake_A = self.g_BA(img_B)\n",
        "\n",
        "    reconstr_A = self.g_BA(fake_B)\n",
        "    reconstr_B = self.g_AB(fake_A)\n",
        "\n",
        "    img_A_id = self.g_BA(img_A)\n",
        "    img_B_id = self.g_AB(img_B)\n",
        "\n",
        "    valid_A = self.d_A(fake_A)\n",
        "    valid_B = self.d_B(fake_B)\n",
        "\n",
        "    self.combined = Model(inputs=[img_A, img_B], outputs=[valid_A, valid_B, reconstr_A, reconstr_B, img_A_id, img_B_id])\n",
        "    self.combined.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'], loss_weights=[1, 1, self.lambda_cycle, self.lambda_cycle, self.lambda_id, self.lambda_id], optimizer=optimizer)\n",
        "\n",
        "  def build_generator(self):\n",
        "    '''U-net generator'''\n",
        "\n",
        "    def conv2d(layer_input, filters, f_size=4):\n",
        "      '''Layers used during downsampling'''\n",
        "      d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "      d = LeakyReLU(alpha=0.2)(d)\n",
        "      d = InstanceNormalization()(d)\n",
        "      return d\n",
        "\n",
        "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
        "      '''Layers used during upsampling'''\n",
        "      u = UpSampling2D(size=2)(layer_input)\n",
        "      u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
        "\n",
        "      if dropout_rate:\n",
        "        u = Dropout(dropout_rate)(u)\n",
        "      u = InstanceNormalization()(u)\n",
        "      u = Concatenate()([u, skip_input])\n",
        "      return u\n",
        "\n",
        "    d0 = Input(shape=self.img_shape)\n",
        "    d1 = conv2d(d0, self.gf)\n",
        "    d2 = conv2d(d1, self.gf * 2)\n",
        "    d3 = conv2d(d2, self.gf * 4)\n",
        "    d4 = conv2d(d3, self.gf * 8)\n",
        "\n",
        "    u1 = deconv2d(d4, d3, self.gf * 4)\n",
        "    u2 = deconv2d(u1, d2, self.gf * 2)\n",
        "    u3 = deconv2d(u2, d1, self.gf)\n",
        "\n",
        "    u4 = UpSampling2D(size=2)(u3)\n",
        "    output_img = Conv2D(self.img_channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
        "\n",
        "    return Model(d0, output_img)\n",
        "\n",
        "  def build_discriminator(self):\n",
        "    def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
        "      '''Discriminator Layer'''\n",
        "      d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "      d = LeakyReLU(alpha=0.2)(d)\n",
        "      if normalization:\n",
        "        d = InstanceNormalization()(d)\n",
        "      return d\n",
        "\n",
        "    img = Input(shape=self.img_shape)\n",
        "    d1 = d_layer(img, self.df, normalization=False)\n",
        "    d2 = d_layer(d1, self.df * 2)\n",
        "    d3 = d_layer(d2, self.df * 4)\n",
        "    d4 = d_layer(d3, self.df * 8)\n",
        "\n",
        "    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
        "\n",
        "    return Model(img, validity)\n",
        "\n",
        "  def train(self, epochs, batch_size=1, sample_interval=50):\n",
        "    start_time = datetime.datetime.now()\n",
        "\n",
        "    valid = np.ones((batch_size, ) + self.disc_patch)\n",
        "\n",
        "    fake = np.zeros((batch_size, ) + self.disc_patch)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_BA.predict(imgs_B)\n",
        "\n",
        "        dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
        "        dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
        "\n",
        "        dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "        dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
        "        dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
        "\n",
        "        dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "        d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "        g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [fake, fake, imgs_A, imgs_B, imgs_A, imgs_B])\n",
        "\n",
        "        if batch_i % sample_interval == 0:\n",
        "          self.sample_images(epoch, batch_i)\n",
        "\n",
        "          # save weights (cannot save model because eager behavior disabled)\n",
        "          self.d_A.save_weights('d_A.weights')\n",
        "          shutil.copy('d_A.weights', os.path.join(project_path, 'd_A.weights'))\n",
        "\n",
        "          self.d_B.save_weights('d_B.weights')\n",
        "          shutil.copy('d_B.weights', os.path.join(project_path, 'd_B.weights'))\n",
        "\n",
        "          self.g_AB.save_weights('g_AB.weights')\n",
        "          shutil.copy('g_AB.weights', os.path.join(project_path, 'g_AB.weights'))\n",
        "\n",
        "          self.g_BA.save_weights('g_BA.weights')\n",
        "          shutil.copy('g_BA.weights', os.path.join(project_path, 'g_BA.weights'))\n",
        "  \n",
        "  def sample_images(self, epoch, batch_i):\n",
        "        r, c = 2, 3\n",
        "\n",
        "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
        "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
        "        \n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_BA.predict(imgs_B)\n",
        "        # Translate back to original domain\n",
        "        reconstr_A = self.g_BA.predict(fake_B)\n",
        "        reconstr_B = self.g_AB.predict(fake_A)\n",
        "\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Original', 'Translated', 'Reconstructed']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[j])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af6YDDpkJNmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = CycleGAN()\n",
        "gan.train(epochs=100, batch_size=64, sample_interval=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdLAaAWqJqjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}