{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hairy_gan.ipynb",
      "provenance": [],
      "mount_file_id": "1PFgBE9Rkd8fOWpAi2lsgE1RrQYJKfdKa",
      "authorship_tag": "ABX9TyMEhBr6mrDy5WjR26bVoOqo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/hairy_gan/blob/master/hairy_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l889X-1JUkaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAT8lea0nmfs",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "500a3d41-d883-4520-c0ac-e8c91e952dd4"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-93ce6061-c42a-49dd-b019-91e9ed957a5a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-93ce6061-c42a-49dd-b019-91e9ed957a5a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"itsgarland2\",\"key\":\"8ff807dec1f05dec1b97d62a072adef8\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb_cPA4QnnNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d jessicali9530/celeba-dataset --force\n",
        "!unzip celeba-dataset.zip\n",
        "!mv img_align_celeba celeba-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPSafu-nrxoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv list_eval_partition.csv celeba-dataset/list_eval_partition.csv\n",
        "!mv list_landmarks_align_celeba.csv celeba-dataset/list_landmarks_align_celeba.csv\n",
        "!mv list_attr_celeba.csv celeba-dataset/list_attr_celeba.csv\n",
        "!mv list_bbox_celeba.csv celeba-dataset/list_bbox_celeba.csv"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAIogfuFtKaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w5WFxuL1Hyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete_df = pd.read_csv('celeba-dataset/list_attr_celeba.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssOSPBRu4k5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "partitions_df = pd.read_csv('celeba-dataset/list_eval_partition.csv') # 0 => train, 1 => validation, 2 => test\n",
        "training_ids_df = partitions_df.loc[partitions_df['partition'] == 0]['image_id']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CizJ-Dm45Xh5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "bc78dff4-6b75-42e6-bcc8-e8aaf4af204b"
      },
      "source": [
        "complete_df[complete_df['image_id'].isin(training_ids_df.tolist())]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>5_o_Clock_Shadow</th>\n",
              "      <th>Arched_Eyebrows</th>\n",
              "      <th>Attractive</th>\n",
              "      <th>Bags_Under_Eyes</th>\n",
              "      <th>Bald</th>\n",
              "      <th>Bangs</th>\n",
              "      <th>Big_Lips</th>\n",
              "      <th>Big_Nose</th>\n",
              "      <th>Black_Hair</th>\n",
              "      <th>Blond_Hair</th>\n",
              "      <th>Blurry</th>\n",
              "      <th>Brown_Hair</th>\n",
              "      <th>Bushy_Eyebrows</th>\n",
              "      <th>Chubby</th>\n",
              "      <th>Double_Chin</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Goatee</th>\n",
              "      <th>Gray_Hair</th>\n",
              "      <th>Heavy_Makeup</th>\n",
              "      <th>High_Cheekbones</th>\n",
              "      <th>Male</th>\n",
              "      <th>Mouth_Slightly_Open</th>\n",
              "      <th>Mustache</th>\n",
              "      <th>Narrow_Eyes</th>\n",
              "      <th>No_Beard</th>\n",
              "      <th>Oval_Face</th>\n",
              "      <th>Pale_Skin</th>\n",
              "      <th>Pointy_Nose</th>\n",
              "      <th>Receding_Hairline</th>\n",
              "      <th>Rosy_Cheeks</th>\n",
              "      <th>Sideburns</th>\n",
              "      <th>Smiling</th>\n",
              "      <th>Straight_Hair</th>\n",
              "      <th>Wavy_Hair</th>\n",
              "      <th>Wearing_Earrings</th>\n",
              "      <th>Wearing_Hat</th>\n",
              "      <th>Wearing_Lipstick</th>\n",
              "      <th>Wearing_Necklace</th>\n",
              "      <th>Wearing_Necktie</th>\n",
              "      <th>Young</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162765</th>\n",
              "      <td>162766.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162766</th>\n",
              "      <td>162767.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162767</th>\n",
              "      <td>162768.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162768</th>\n",
              "      <td>162769.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162769</th>\n",
              "      <td>162770.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162770 rows Ã— 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          image_id  5_o_Clock_Shadow  ...  Wearing_Necktie  Young\n",
              "0       000001.jpg                -1  ...               -1      1\n",
              "1       000002.jpg                -1  ...               -1      1\n",
              "2       000003.jpg                -1  ...               -1      1\n",
              "3       000004.jpg                -1  ...               -1      1\n",
              "4       000005.jpg                -1  ...               -1      1\n",
              "...            ...               ...  ...              ...    ...\n",
              "162765  162766.jpg                -1  ...               -1      1\n",
              "162766  162767.jpg                -1  ...               -1     -1\n",
              "162767  162768.jpg                 1  ...                1      1\n",
              "162768  162769.jpg                -1  ...               -1      1\n",
              "162769  162770.jpg                -1  ...               -1      1\n",
              "\n",
              "[162770 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLXq8rus1Pm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "black_hair_ids = complete_df.loc[complete_df['Black_Hair'] == 1]['image_id'].tolist() # filters out black hair candidates\n",
        "blond_hair_ids = complete_df.loc[complete_df['Blond_Hair'] == 1]['image_id'].tolist() # filters out blond hair candidates"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG-Pz8Wg7PpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir celeba-dataset/trainA\n",
        "!mkdir celeba-dataset/trainB"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgCLyX_s76x_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for id in black_hair_ids:\n",
        "  shutil.copy(os.path.join('celeba-dataset/img_align_celeba', id), os.path.join('celeba-dataset', 'trainA', id))\n",
        "\n",
        "for id in blond_hair_ids:\n",
        "  shutil.copy(os.path.join('celeba-dataset/img_align_celeba', id), os.path.join('celeba-dataset', 'trainB', id))  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx48KI7NvB9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && cd keras-contrib \\\n",
        "    && pip install git+https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && python convert_to_tf_keras.py \\\n",
        "    && USE_TF_KERAS=1 python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_tQXJCU83oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import glob as glob"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpW0Uqm7v6y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, dataset_name, img_res):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "\n",
        "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
        "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
        "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs = []\n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "\n",
        "        return imgs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"val\"\n",
        "        path_A = glob('%s/%sA/*' % (self.dataset_name, data_type))\n",
        "        path_B = glob('%s/%sB/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        # Sample n_batches * batch_size from each path list so that model sees all\n",
        "        # samples from both domains\n",
        "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
        "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
        "\n",
        "        for i in range(self.n_batches-1):\n",
        "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
        "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
        "            imgs_A, imgs_B = [], []\n",
        "            for img_A, img_B in zip(batch_A, batch_B):\n",
        "                img_A = self.imread(img_A)\n",
        "                img_B = self.imread(img_B)\n",
        "\n",
        "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
        "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img_A = np.fliplr(img_A)\n",
        "                        img_B = np.fliplr(img_B)\n",
        "\n",
        "                imgs_A.append(img_A)\n",
        "                imgs_B.append(img_B)\n",
        "\n",
        "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "            yield imgs_A, imgs_B\n",
        "\n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode='RGB').astype(np.float)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSbgXa0M9aWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HairyGan(): # based on CycleGan\n",
        "  def __init__(self):\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.img_channels = 3\n",
        "\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
        "    \n",
        "    patch = int(self.img_rows / 2**4)\n",
        "    disc_out = (patch, patch, 1) # output shape of discriminator\n",
        "    self.d_out_shape = (batch_size, ) + disc_out\n",
        "\n",
        "    self.data_loader = DataLoader(dataset_name='celeba-dataset', img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "    self.optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "    # discriminators\n",
        "    self.d_A = self.build_discriminator()\n",
        "    self.d_B = self.build_discriminator()\n",
        "\n",
        "    self.d_A.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "    self.d_B.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    # generators\n",
        "    self.g_AB = self.build_generator()\n",
        "    self.g_BA = self.build_generator()\n",
        "\n",
        "    self.combined_model = self.build_combined()\n",
        "\n",
        "  def build_combined(self):\n",
        "    lambda_cycle = 10.\n",
        "    lambda_id = 0.9 * lambda_cycle\n",
        "\n",
        "    img_A = Input(shape=self.img_shape) # image from domain A\n",
        "    img_B = Input(shape=self.img_shape) # image from domain B\n",
        "\n",
        "    fake_A = self.g_BA(img_B)\n",
        "    fake_B = self.g_AB(img_A)\n",
        "    \n",
        "    reconstr_A = self.g_BA(fake_B)\n",
        "    reconstr_B = self.g_AB(fake_A)\n",
        "\n",
        "    id_A = self.g_BA(img_A)\n",
        "    id_B = self.g_AB(img_B)\n",
        "\n",
        "    valid_A = self.d_A(fake_A)\n",
        "    valid_B = self.d_B(fake_B)\n",
        "\n",
        "    combined = Model(\n",
        "        inputs=[img_A, img_B],\n",
        "        outputs=[valid_A, valid_B, reconstr_A, reconstr_B, id_A, id_B]\n",
        "    )\n",
        "\n",
        "    combined.compile(\n",
        "        loss=['mse', 'mse', 'mae', 'mae', 'mae'],\n",
        "        loss_weights=[1, 1, lambda_cycle, lambda_cycle, lambda_id, lambda_id],\n",
        "        optimizer=self.optimizer\n",
        "    )\n",
        "\n",
        "    return combined\n",
        "\n",
        "  def build_discriminator(self):\n",
        "\n",
        "    def d_conv_block(layer_input, num_filt, f_size=4, normalization=True):\n",
        "      d = Conv2D(num_filt, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "      d = LeakyReLU(alpha=0.2)(d)\n",
        "      if normalization:\n",
        "        d = InstanceNormalization()(d)\n",
        "\n",
        "      return d\n",
        "\n",
        "    num_filt = 64\n",
        "\n",
        "    img = Input(shape=self.img_shape)\n",
        "    d1 = d_conv_block(img, num_filt, normalization=False)\n",
        "    d2 = d_conv_block(d1, num_filt * 2)\n",
        "    d3 = d_conv_block(d2, num_filt * 4)\n",
        "    d4 = d_conv_block(d3, num_filt * 8)\n",
        "    output = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
        "\n",
        "    return Model(img, output)\n",
        "\n",
        "  def build_generator(self):\n",
        "    def g_conv_block(layer_input, num_filt, f_size=4):\n",
        "      d = Conv2D(num_filt, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "      d = LeakyReLU(alpha=0.2)(d)\n",
        "      d = InstanceNormalization()(d)\n",
        "      return d\n",
        "\n",
        "    def g_deconv_block(layer_input, skip_input, num_filt, f_size=4, dropout_rate=0):\n",
        "      u = UpSampling2D(size=2)(layer_input)\n",
        "      u = Conv2D(num_filt, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
        "      \n",
        "      if dropout_rate:\n",
        "        u = Dropout(dropout_rate)(u)\n",
        "      \n",
        "      u = InstanceNormalization()(u)\n",
        "      u = Concatenate()([u, skip_input])\n",
        "\n",
        "      return u\n",
        "\n",
        "    num_filt =  32\n",
        "\n",
        "    d0 = Input(shape=self.img_shape)\n",
        "    d1 = g_conv_block(d0, num_filt)\n",
        "    d2 = g_conv_block(d1, num_filt * 2)\n",
        "    d3 = g_conv_block(d2, num_filt * 4)\n",
        "    d4 = g_conv_block(d3, num_filt * 8)\n",
        "\n",
        "    u1 = g_deconv_block(d4, d3, num_filt * 4)\n",
        "    u2 = g_deconv_block(u1, d2, num_filt * 2)\n",
        "    u3 = g_deconv_block(u2, d1, num_filt)\n",
        "\n",
        "    u4 = UpSampling2D(size=2)(u3)\n",
        "    output = Conv2D(self.img_channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
        "\n",
        "    return Model([d0, output])\n",
        "\n",
        "\n",
        "  def train(self, epochs, batch_size=1, sample_interval=50):\n",
        "    valid = np.ones(self.d_out_shape)\n",
        "    fake = np.zeros(self.d_out_shape)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
        "        fake_A = self.g_BA(imgs_B)\n",
        "        fake_B = self.g_AB(imgs_A)\n",
        "\n",
        "        real_A_loss = self.d_A.train_on_batch(imgs_A, valid)\n",
        "        real_B_loss = self.d_B.train_on_batch(imgs_B, valid)\n",
        "\n",
        "        fake_A_loss = self.d_A.train_on_batch(fake_A, fake)\n",
        "        fake_B_loss = self.d_B.train_on_batch(fake_B, fake)\n",
        "\n",
        "        d_A_loss = 0.5 * np.add(real_A_loss, fake_A_loss)\n",
        "        d_B_loss = 0.5 * np.add(real_B_loss, fake_B_loss)\n",
        "\n",
        "        d_loss = 0.5 * np.add(d_A_loss, d_B_loss)\n",
        "\n",
        "        g_loss = self.combined_model.train_on_batch(\n",
        "            [imgs_A, imgs_B],\n",
        "            [fake, fake, imgs_A, imgs_B, imgs_A, imgs_B]\n",
        "        )\n",
        "\n",
        "        if batch_i % sample_interval == 0:\n",
        "          self.sample_images(epoch, batch_i)\n",
        "\n",
        "  def sample_images(self, epoch, batch_i):\n",
        "    pass\n",
        "\n",
        "    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCeFNls66FAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}