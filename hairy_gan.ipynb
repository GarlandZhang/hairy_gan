{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hairy_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PFgBE9Rkd8fOWpAi2lsgE1RrQYJKfdKa",
      "authorship_tag": "ABX9TyNdMzLAhaAQXppIb/fr293V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/hairy_gan/blob/master/hairy_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb_cPA4QnnNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "if not os.path.exists('kaggle.json'):\n",
        "  shutil.copy('/content/drive/My Drive/hairy_gan/kaggle.json', 'kaggle.json')\n",
        "  # !pip install -q kaggle\n",
        "  # files.upload()\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !kaggle datasets download -d jessicali9530/celeba-dataset --force\n",
        "  !unzip celeba-dataset.zip\n",
        "  !mv img_align_celeba celeba-dataset\n",
        "  !mv list_eval_partition.csv celeba-dataset/list_eval_partition.csv\n",
        "  !mv list_landmarks_align_celeba.csv celeba-dataset/list_landmarks_align_celeba.csv\n",
        "  !mv list_attr_celeba.csv celeba-dataset/list_attr_celeba.csv\n",
        "  !mv list_bbox_celeba.csv celeba-dataset/list_bbox_celeba.csv\n",
        "\n",
        "  !mkdir celeba-dataset/train\n",
        "  !mkdir celeba-dataset/validation\n",
        "  !mkdir celeba-dataset/test\n",
        "\n",
        "  partitions_df = pd.read_csv('celeba-dataset/list_eval_partition.csv') # 0 => train, 1 => validation, 2 => test\n",
        "  for i, set_name in enumerate(['train', 'validation', 'test']):\n",
        "    set_ids_df = partitions_df.loc[partitions_df['partition'] == i]['image_id']\n",
        "    set_ids = set_ids_df.tolist()\n",
        "    for id in set_ids:\n",
        "      shutil.copy(os.path.join('celeba-dataset/img_align_celeba', id), os.path.join('celeba-dataset', f'{set_name}', id))\n",
        "\n",
        "  !git clone https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && cd keras-contrib \\\n",
        "    && pip install git+https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && python convert_to_tf_keras.py \\\n",
        "    && USE_TF_KERAS=1 python setup.py install\n",
        "\n",
        "  !pip install scipy==1.1.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_tQXJCU83oV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a1561717-91c3-47f4-ed09-eb1ce6d0e996"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Embedding\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model, save_model\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.backend import set_session, clear_session\n",
        "# from tensorflow.python.keras.models import load_model\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "tf.compat.v1.disable_v2_behavior()\n",
        "# tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlMUoX4ES1Ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r celeba-dataset/train_filter\n",
        "!mkdir celeba-dataset/train_filter\n",
        "# extract images of particular class for training\n",
        "num_images_each = 5\n",
        "feature = 'Bald'\n",
        "complete_df = pd.read_csv('celeba-dataset/list_attr_celeba.csv')\n",
        "for img_id in complete_df.loc[complete_df[feature] == 1][:num_images_each].filter(['image_id']).to_numpy():\n",
        "  img_id = img_id[0]\n",
        "  shutil.copy(f'celeba-dataset/train/{img_id}', f'celeba-dataset/train_filter/{img_id}')\n",
        "\n",
        "for img_id in complete_df.loc[complete_df[feature] == -1][:num_images_each].filter(['image_id']).to_numpy():\n",
        "  img_id = img_id[0]\n",
        "  shutil.copy(f'celeba-dataset/train/{img_id}', f'celeba-dataset/train_filter/{img_id}')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpW0Uqm7v6y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, dataset_name, img_res):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "        self.complete_df = pd.read_csv('celeba-dataset/list_attr_celeba.csv')\n",
        "        # self.features = ['Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Bushy_Eyebrows', 'Eyeglasses', 'Gender', 'Mouth_Open', 'Mustache', 'No_Beard', 'Pale_Skin', 'Age']\n",
        "        # self.num_attrs = 9 # should equal to length of self.features\n",
        "        self.features = ['Bald']\n",
        "        self.num_attrs = len(self.features)\n",
        "\n",
        "    def load_data(self, dataset_type, batch_size=1, is_testing=False):\n",
        "        data_type = dataset_type\n",
        "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs = []\n",
        "        attribs = []\n",
        "        \n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "            # get attributes\n",
        "\n",
        "            img_attribs = [(val + 1) // 2 for val in self.complete_df.loc[self.complete_df['image_id'] == os.path.basename(img_path)].filter(items=self.features).to_numpy()[0]]\n",
        "\n",
        "            attribs.append(img_attribs)\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "        attribs = np.array(attribs)\n",
        "\n",
        "        return imgs, attribs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False, is_filter=False):\n",
        "        if is_filter:\n",
        "          data_type = 'train_filter'\n",
        "        elif is_testing:\n",
        "          data_type = 'test'\n",
        "        else:\n",
        "          data_type = 'train'\n",
        "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        self.n_batches = int(len(path) / batch_size)\n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        path = np.random.choice(path, total_samples, replace=False)\n",
        "\n",
        "        i = 0\n",
        "        while i < self.n_batches - 1:\n",
        "            batch = path[i*batch_size:(i+1)*batch_size]\n",
        "            imgs = []\n",
        "            attribs = []\n",
        "            for img_path in batch:\n",
        "                img = self.imread(img_path)\n",
        "\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img = np.fliplr(img)\n",
        "\n",
        "                imgs.append(img)\n",
        "\n",
        "                # get attributes\n",
        "\n",
        "                img_attribs = np.array([(val + 1) // 2 for val in self.complete_df.loc[self.complete_df['image_id'] == os.path.basename(img_path)].filter(items=self.features).to_numpy()[0]])\n",
        "\n",
        "                attribs.append(img_attribs)\n",
        "\n",
        "            imgs = np.array(imgs)/127.5 - 1.\n",
        "            attribs = np.array(attribs)\n",
        "\n",
        "            i += 1\n",
        "            if i == self.n_batches - 1:\n",
        "              # reset\n",
        "              path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "              path = np.random.choice(path, total_samples, replace=False)\n",
        "              i = 0\n",
        "\n",
        "            yield imgs, attribs\n",
        "\n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode='RGB').astype(np.float)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwT3pToianO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_encoder(img_shape, num_filters=64, kernel_size=4, strides=2):\n",
        "  def build_conv(x, num_filters, kernel_size, strides):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "  img = Input(shape=img_shape)\n",
        "  x = build_conv(img, num_filters, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 2, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 4, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 8, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 16, kernel_size, strides)\n",
        "  # x.name = 'encoder_output'\n",
        "\n",
        "  model = Model(img, x, name='encoder')\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def build_embedding(img, label, input_shape, attr_size):\n",
        "  label_embedding = Embedding(2, np.prod(input_shape), input_length=attr_size)(label)\n",
        "  # style_embedding = Embedding(2, np.prod(input_shape), input_length=attr_size)(style)\n",
        "  # label_style_embedding = Add()([label_embedding, style_embedding])\n",
        "  # label_style_embedding = Reshape(input_shape[:-1] + (attr_size * input_shape[-1], ))(label_style_embedding)\n",
        "  # emb_img = Concatenate(axis=-1)([img, label_style_embedding])\n",
        "  label_embedding = Reshape(input_shape[:-1] + (attr_size * input_shape[-1], ))(label_embedding)\n",
        "  emb_img = Concatenate(axis=-1)([img, label_embedding])\n",
        "  return emb_img\n",
        "\n",
        "def build_decoder(latent_space_shape, attr_size, num_filters=64, kernel_size=4, strides=1):\n",
        "  def build_deconv(x, num_filters, kernel_size, strides):\n",
        "    x = UpSampling2D(size=2)(x)\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "  img = Input(shape=latent_space_shape)\n",
        "  label = Input(shape=(attr_size, ), dtype='int32')\n",
        "\n",
        "  emb_img = build_embedding(img, label, latent_space_shape, attr_size)\n",
        "\n",
        "  x = build_deconv(emb_img, num_filters * 16, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 8, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 4, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 2, kernel_size=kernel_size, strides=strides)\n",
        "  x = UpSampling2D(size=2)(x)\n",
        "  x = Conv2D(3, kernel_size=kernel_size, strides=strides, padding='same', activation='tanh')(x)\n",
        "  # x.name = 'decoder_output'\n",
        "\n",
        "  model = Model([img, label], x, name='decoder')\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def build_convnet(img, num_filters=64, kernel_size=4, strides=2):\n",
        "  def build_conv(x, num_filters, kernel_size, strides):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = InstanceNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "  \n",
        "  x = build_conv(img, num_filters, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 2, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 4, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 8, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 16, kernel_size, strides)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024)(x)\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def build_dc(img_shape, attr_size, optimizer): # NOTE: we ignore inputting original image to discriminator head. why? cause im not sure if its important\n",
        "  img = Input(shape=img_shape)\n",
        "  label = Input(shape=(attr_size, ), dtype='int32') # I don't understand. why do we have this?\n",
        "\n",
        "  # emb_img = build_embedding(img, label, img_shape, attr_size)\n",
        "  # x = build_convnet(emb_img)\n",
        "  x = build_convnet(img)\n",
        "  disc_output = Dense(1, name='disc_output')(x)\n",
        "  classif_output = Dense(attr_size, activation='sigmoid', name='classif_output')(x)\n",
        "\n",
        "  dc = Model([img, label], [disc_output, classif_output], name='dc')\n",
        "\n",
        "  dc.compile(loss=['binary_crossentropy', 'binary_crossentropy'], loss_weights=[1, 1], optimizer=optimizer)\n",
        "\n",
        "  dc.summary()\n",
        "\n",
        "  return dc\n",
        "\n",
        "def build_combined_generator(img_shape, attr_size, genc, gdec, dc, optimizer):\n",
        "  dc.trainable = False\n",
        "\n",
        "  x_a = Input(shape=img_shape) # original image\n",
        "  a = Input(shape=(attr_size, )) # original attr\n",
        "  b = Input(shape=(attr_size, )) # requested attr\n",
        "  \n",
        "  z = genc(x_a) # latent space representation of original image\n",
        "  x_b = gdec([z, b]) # image with requested attr\n",
        "\n",
        "  valid, b_hat = dc([x_b, b]) # guess real or fake and guess the requested features \n",
        "\n",
        "  x_a_hat = gdec([z, a]) # reconstr\n",
        "\n",
        "  combined = Model(\n",
        "      inputs=[x_a, a, b],\n",
        "      outputs=[b_hat, valid, x_a_hat],\n",
        "      name='combined'\n",
        "  )\n",
        "\n",
        "  combined.compile(loss=['binary_crossentropy', 'binary_crossentropy', 'mae'], loss_weights=[10, 1, 100], optimizer=optimizer)\n",
        "\n",
        "  combined.summary()\n",
        "\n",
        "  return combined"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh62XJlhZSTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle(elems):\n",
        "  new_elems = elems.copy()\n",
        "  np.random.shuffle(new_elems)\n",
        "  return new_elems\n",
        "\n",
        "def create_random_attrs(attrs, count):\n",
        "  attr_size = attrs[0].size\n",
        "  \n",
        "  new_attrs = np.random.randint(0, 2, size=(count, attr_size))\n",
        "  for r in range(count):\n",
        "    for c in range(attr_size):\n",
        "      if attrs[r, c] == 1 and new_attrs[r, c] == 0:\n",
        "        new_attrs[r, c] = 1\n",
        "  \n",
        "  return new_attrs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1S3__xyoSCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_dc_step(batch_size, gen_batch, genc, gdec, dc):\n",
        "  imgs, attrs, new_attrs = gen_batch\n",
        "\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  x_a = imgs\n",
        "  a = attrs\n",
        "  b = new_attrs\n",
        "\n",
        "  z = genc.predict(x_a)\n",
        "  x_b_hat = gdec.predict([z, b])\n",
        "\n",
        "  dc_real_history = dc.fit([x_a, a], [real, a])\n",
        "  dc_fake_history = dc.fit([x_b_hat, b], [fake, b])\n",
        "\n",
        "  return dc_real_history, dc_fake_history\n",
        "\n",
        "def train_encdec_step(batch_size, gen_batch, combined):\n",
        "  imgs, attrs, new_attrs = gen_batch\n",
        "\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  x_a = imgs\n",
        "  a = attrs\n",
        "  b = new_attrs\n",
        "\n",
        "  g_real_history = combined.fit([x_a, a, b], [b, fake, x_a])\n",
        "\n",
        "  return g_real_history"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSbgXa0M9aWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HairyGan(): # based on AttGan\n",
        "  def __init__(self, flags={}):\n",
        "\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.img_channels = 3\n",
        "\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
        "    \n",
        "    patch = int(self.img_rows / 2**4)\n",
        "    self.disc_out = (patch, patch, 1) # output shape of discriminator\n",
        "\n",
        "    self.dl = DataLoader(dataset_name='celeba-dataset', img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "    self.optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "    self.flags = flags\n",
        "\n",
        "    if flags['filter_on']:\n",
        "      self.enc = build_encoder(self.img_shape)\n",
        "      self.dec = build_decoder((4, 4, 1024), self.dl.num_attrs)\n",
        "      self.dc = build_dc(self.img_shape, self.dl.num_attrs, self.optimizer)\n",
        "      self.combined = build_combined_generator(self.img_shape, self.dl.num_attrs, self.enc, self.dec, self.dc, self.optimizer)   \n",
        "\n",
        "    else:\n",
        "      if os.path.exists(os.path.join(project_path, 'enc.h5')):\n",
        "        print('Loading encoder from file')\n",
        "        self.enc = load_model(os.path.join(project_path, 'enc.h5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "      else:\n",
        "        self.enc = build_encoder(self.img_shape)\n",
        "      \n",
        "      if os.path.exists(os.path.join(project_path, 'dec.h5')):\n",
        "        print('Loading decoder from file')\n",
        "        self.dec = load_model(os.path.join(project_path, 'dec.h5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "      else:\n",
        "        self.dec = build_decoder((4, 4, 1024), self.dl.num_attrs)\n",
        "\n",
        "      self.dc = build_dc(self.img_shape, self.dl.num_attrs, self.optimizer)\n",
        "      \n",
        "      if os.path.exists(os.path.join(project_path, 'dc.weights')):\n",
        "        print('Loading dc from file')\n",
        "        self.dc.load_weights(os.path.join(project_path, 'dc.weights'))\n",
        "\n",
        "      self.combined = build_combined_generator(self.img_shape, self.dl.num_attrs, self.enc, self.dec, self.dc, self.optimizer)   \n",
        "\n",
        "    self.metrics = {}\n",
        "\n",
        "  def train(self, num_epochs, batch_size, visualize_interval):\n",
        "    # set up data loader\n",
        "    batch_gen = self.dl.load_batch(batch_size=batch_size, is_filter=self.flags['filter_on'])\n",
        "    for i, elem in enumerate(batch_gen):\n",
        "      break\n",
        "  \n",
        "    num_batches = self.dl.n_batches\n",
        "    steps_per_epoch = num_batches\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      for step in tqdm(range(steps_per_epoch), desc=f'Train {epoch} / {num_epochs}', total=steps_per_epoch):\n",
        "        imgs, attrs = next(batch_gen)\n",
        "        new_attrs = create_random_attrs(attrs, batch_size)\n",
        "        gen_batch = (imgs, attrs, new_attrs)\n",
        "\n",
        "        dc_real_history, dc_fake_history = train_dc_step(batch_size, gen_batch, self.enc, self.dec, self.dc)\n",
        "        g_real_history = train_encdec_step(batch_size, gen_batch, self.combined)\n",
        "\n",
        "        dc_real_history.history['dc_real_loss'] = dc_real_history.history.pop('loss')\n",
        "        dc_fake_history.history['dc_fake_loss'] = dc_fake_history.history.pop('loss')\n",
        "        g_real_history.history['g_real_loss'] = g_real_history.history.pop('loss')\n",
        "\n",
        "        self.metrics = add_metrics(self.metrics, [dc_real_history, dc_fake_history, g_real_history])\n",
        "\n",
        "        if (step + 1) % visualize_interval == 0:\n",
        "          try:\n",
        "            self.sample_images(epoch, step, is_filter=self.flags['filter_on'])\n",
        "            \n",
        "            # save models\n",
        "            # save_model(self.enc, 'enc.h5')\n",
        "            # shutil.copy('enc.h5', os.path.join(project_path, 'enc.h5'))\n",
        "\n",
        "            # save_model(self.dec, 'dec.h5')\n",
        "            # shutil.copy('dec.h5', os.path.join(project_path, 'dec.h5'))\n",
        "\n",
        "            # self.dc.save_weights('dc.weights')\n",
        "            # shutil.copy('dc.weights', os.path.join(project_path, 'dc.weights'))\n",
        "\n",
        "            # self.combined.save_weights('combined.weights')\n",
        "            # shutil.copy('combined.weights', os.path.join(project_path, 'combined.weights'))\n",
        "\n",
        "            # visualize loss/accuracy\n",
        "            visualize_metrics(self.metrics)\n",
        "          except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "  def sample_images(self, epoch, batch_i, is_filter=False):\n",
        "    print(f'Epoch: {epoch} with batch: {batch_i}')\n",
        "    rows, cols = 2, 3\n",
        "\n",
        "    imgs, attrs = self.dl.load_data('test' if not is_filter else 'train_filter', batch_size=2, is_testing=True)\n",
        "\n",
        "    new_attrs = create_random_attrs(attrs, attrs.shape[0])\n",
        "\n",
        "    encodings = self.enc.predict(imgs)\n",
        "\n",
        "    reconstrs = self.dec.predict([encodings, attrs])\n",
        "\n",
        "    new_imgs = self.dec.predict([encodings, new_attrs])\n",
        "    # combined.predict([imgs, attrs, new_attrs]) \n",
        "\n",
        "    gen_imgs = np.array([imgs[0], new_imgs[0], reconstrs[0], imgs[1], new_imgs[1], reconstrs[1]])\n",
        "\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    titles = ['Original', 'Translated', 'Reconstructed']\n",
        "    fig, axes = plt.subplots(rows, cols)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for i in range(rows):\n",
        "      for j in range(cols):\n",
        "        axes[i, j].imshow(gen_imgs[count])\n",
        "        axes[i, j].set_title(titles[j])\n",
        "        axes[i, j].axis('off')\n",
        "        count += 1\n",
        "\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LiPqnQqm6B7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_metrics(metrics, histories):\n",
        "  for history in histories:\n",
        "    for k, v in history.history.items():\n",
        "      if metrics.get(k) is None:\n",
        "        metrics[k] = v\n",
        "      else:\n",
        "        metrics[k].append(v[0]) # array of 1 elem => elem\n",
        "  return metrics"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJeIkMXPtnjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_metrics(metrics):\n",
        "  num_plots = len(metrics.keys())\n",
        "\n",
        "  fig, axes = plt.subplots(num_plots)\n",
        "\n",
        "  for pl, (title, values) in enumerate(metrics.items()):\n",
        "    axes[pl].plot(values)\n",
        "    axes[pl].set_title(title)\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCeFNls66FAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9544313-1724-4af7-bc62-6bc7d3b799dd"
      },
      "source": [
        "project_path = '/content/drive/My Drive/hairy_gan'\n",
        "flags = { 'filter_on': True }\n",
        "gan = HairyGan(flags)\n",
        "gan.train(num_epochs=30, batch_size=2, visualize_interval=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_62 (InputLayer)        (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 64, 64, 64)        3136      \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_112 (LeakyReLU)  (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 32, 32, 128)       131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_113 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 16, 16, 256)       524544    \n",
            "_________________________________________________________________\n",
            "batch_normalization_66 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_114 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 8, 8, 512)         2097664   \n",
            "_________________________________________________________________\n",
            "batch_normalization_67 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_115 (LeakyReLU)  (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 4, 4, 1024)        8389632   \n",
            "_________________________________________________________________\n",
            "batch_normalization_68 (Batc (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_116 (LeakyReLU)  (None, 4, 4, 1024)        0         \n",
            "=================================================================\n",
            "Total params: 11,154,112\n",
            "Trainable params: 11,150,144\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_64 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 1, 16384)     32768       input_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_63 (InputLayer)           (None, 4, 4, 1024)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 4, 4, 1024)   0           embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 4, 4, 2048)   0           input_63[0][0]                   \n",
            "                                                                 reshape_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_36 (UpSampling2D) (None, 8, 8, 2048)   0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 8, 8, 1024)   33555456    up_sampling2d_36[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 1024)   4096        conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_117 (LeakyReLU)     (None, 8, 8, 1024)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_37 (UpSampling2D) (None, 16, 16, 1024) 0           leaky_re_lu_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 512)  8389120     up_sampling2d_37[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 16, 16, 512)  2048        conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_118 (LeakyReLU)     (None, 16, 16, 512)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_38 (UpSampling2D) (None, 32, 32, 512)  0           leaky_re_lu_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 256)  2097408     up_sampling2d_38[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 32, 32, 256)  1024        conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_119 (LeakyReLU)     (None, 32, 32, 256)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_39 (UpSampling2D) (None, 64, 64, 256)  0           leaky_re_lu_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 64, 64, 128)  524416      up_sampling2d_39[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 64, 64, 128)  512         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_120 (LeakyReLU)     (None, 64, 64, 128)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_40 (UpSampling2D) (None, 128, 128, 128 0           leaky_re_lu_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 128, 128, 3)  6147        up_sampling2d_40[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 44,612,995\n",
            "Trainable params: 44,609,155\n",
            "Non-trainable params: 3,840\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"dc\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_65 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 64, 64, 64)   3136        input_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_49 (Inst (None, 64, 64, 64)   2           conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_121 (LeakyReLU)     (None, 64, 64, 64)   0           instance_normalization_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 32, 32, 128)  131200      leaky_re_lu_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_50 (Inst (None, 32, 32, 128)  2           conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_122 (LeakyReLU)     (None, 32, 32, 128)  0           instance_normalization_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 256)  524544      leaky_re_lu_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_51 (Inst (None, 16, 16, 256)  2           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_123 (LeakyReLU)     (None, 16, 16, 256)  0           instance_normalization_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 8, 8, 512)    2097664     leaky_re_lu_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_52 (Inst (None, 8, 8, 512)    2           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_124 (LeakyReLU)     (None, 8, 8, 512)    0           instance_normalization_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 4, 4, 1024)   8389632     leaky_re_lu_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_53 (Inst (None, 4, 4, 1024)   2           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_125 (LeakyReLU)     (None, 4, 4, 1024)   0           instance_normalization_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 16384)        0           leaky_re_lu_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1024)         16778240    flatten_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_54 (Inst (None, 1024)         2           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_126 (LeakyReLU)     (None, 1024)         0           instance_normalization_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "disc_output (Dense)             (None, 1)            1025        leaky_re_lu_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "classif_output (Dense)          (None, 1)            1025        leaky_re_lu_126[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 27,926,478\n",
            "Trainable params: 27,926,478\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:90: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "\n",
            "\n",
            "\n",
            "Train 0 / 30:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"combined\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_67 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Model)                 (None, 4, 4, 1024)   11154112    input_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_69 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Model)                 (None, 128, 128, 3)  44612995    encoder[1][0]                    \n",
            "                                                                 input_69[0][0]                   \n",
            "                                                                 encoder[1][0]                    \n",
            "                                                                 input_68[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_68 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dc (Model)                      [(None, 1), (None, 1 27926478    decoder[1][0]                    \n",
            "                                                                 input_69[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 83,693,585\n",
            "Trainable params: 55,759,299\n",
            "Non-trainable params: 27,934,286\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2/2 [==============================] - 2s 962ms/step - loss: 16.5328 - disc_output_loss: 15.4249 - classif_output_loss: 1.1078\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 6.9296e-10 - disc_output_loss: 0.0000e+00 - classif_output_loss: 6.9296e-10\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 8s 4s/step - loss: 71.0479 - dc_loss: 0.0000e+00 - decoder_loss: 0.7105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Train 0 / 30:  20%|██        | 1/5 [00:37<02:30, 37.60s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 39.3121 - disc_output_loss: 15.4249 - classif_output_loss: 23.8871\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 10.3940 - disc_output_loss: 0.0147 - classif_output_loss: 10.3793\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 7s 3s/step - loss: 53.1637 - dc_loss: 0.0000e+00 - decoder_loss: 0.5315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Train 0 / 30:  40%|████      | 2/5 [00:46<01:26, 28.96s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 329ms/step - loss: 17.1134 - disc_output_loss: 15.4249 - classif_output_loss: 1.6885\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 332ms/step - loss: 0.1227 - disc_output_loss: 0.0000e+00 - classif_output_loss: 0.1227\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 7s 3s/step - loss: 53.4631 - dc_loss: 0.0000e+00 - decoder_loss: 0.5338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Train 0 / 30:  60%|██████    | 3/5 [00:55<00:45, 22.88s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 324ms/step - loss: 20.1246 - disc_output_loss: 15.4249 - classif_output_loss: 4.6996\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 329ms/step - loss: 0.2979 - disc_output_loss: 0.0000e+00 - classif_output_loss: 0.2979\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 7s 3s/step - loss: 65.6610 - dc_loss: 0.0000e+00 - decoder_loss: 0.5804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Train 0 / 30:  80%|████████  | 4/5 [01:03<00:18, 18.61s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 20.0348 - disc_output_loss: 15.4249 - classif_output_loss: 4.6099\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 324ms/step - loss: 1.0223 - disc_output_loss: 0.0000e+00 - classif_output_loss: 1.0223\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 7s 3s/step - loss: 74.0584 - dc_loss: 0.0000e+00 - decoder_loss: 0.6356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Train 0 / 30: 100%|██████████| 5/5 [01:12<00:00, 14.48s/it]\n",
            "\n",
            "\n",
            "\n",
            "Train 1 / 30:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 16.6567 - disc_output_loss: 15.4249 - classif_output_loss: 1.2318\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 332ms/step - loss: 0.3246 - disc_output_loss: 0.0000e+00 - classif_output_loss: 0.3246\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 7s 3s/step - loss: 74.7354 - dc_loss: 0.0000e+00 - decoder_loss: 0.6655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Train 1 / 30:  20%|██        | 1/5 [00:08<00:34,  8.67s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFBh_xEHdiKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.sample_images(1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdI0NX6KMT-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}