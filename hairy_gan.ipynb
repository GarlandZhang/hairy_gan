{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hairy_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PFgBE9Rkd8fOWpAi2lsgE1RrQYJKfdKa",
      "authorship_tag": "ABX9TyM5e+InrkNPLUgmR7oHHG5D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/hairy_gan/blob/master/hairy_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb_cPA4QnnNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "if not os.path.exists('kaggle.json'):\n",
        "  shutil.copy('/content/drive/My Drive/hairy_gan/kaggle.json', 'kaggle.json')\n",
        "  # !pip install -q kaggle\n",
        "  # files.upload()\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !kaggle datasets download -d jessicali9530/celeba-dataset --force\n",
        "  !unzip celeba-dataset.zip\n",
        "  !mv img_align_celeba celeba-dataset\n",
        "  !mv list_eval_partition.csv celeba-dataset/list_eval_partition.csv\n",
        "  !mv list_landmarks_align_celeba.csv celeba-dataset/list_landmarks_align_celeba.csv\n",
        "  !mv list_attr_celeba.csv celeba-dataset/list_attr_celeba.csv\n",
        "  !mv list_bbox_celeba.csv celeba-dataset/list_bbox_celeba.csv\n",
        "\n",
        "  !mkdir celeba-dataset/train\n",
        "  !mkdir celeba-dataset/validation\n",
        "  !mkdir celeba-dataset/test\n",
        "\n",
        "  partitions_df = pd.read_csv('celeba-dataset/list_eval_partition.csv') # 0 => train, 1 => validation, 2 => test\n",
        "  for i, set_name in enumerate(['train', 'validation', 'test']):\n",
        "    set_ids_df = partitions_df.loc[partitions_df['partition'] == i]['image_id']\n",
        "    set_ids = set_ids_df.tolist()\n",
        "    for id in set_ids:\n",
        "      shutil.copy(os.path.join('celeba-dataset/img_align_celeba', id), os.path.join('celeba-dataset', f'{set_name}', id))\n",
        "\n",
        "  !git clone https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && cd keras-contrib \\\n",
        "    && pip install git+https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && python convert_to_tf_keras.py \\\n",
        "    && USE_TF_KERAS=1 python setup.py install\n",
        "\n",
        "  !pip install scipy==1.1.0"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_tQXJCU83oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Embedding\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.backend import set_session\n",
        "# from tensorflow.python.keras.models import load_model\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpW0Uqm7v6y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, dataset_name, img_res):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "        self.complete_df = pd.read_csv('celeba-dataset/list_attr_celeba.csv')\n",
        "        self.features = ['Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Bushy_Eyebrows', 'Eyeglasses', 'Gender', 'Mouth_Open', 'Mustache', 'No_Beard', 'Pale_Skin', 'Age']\n",
        "        self.num_attrs = 9 # should equal to length of self.features\n",
        "\n",
        "    def load_data(self, dataset_type, batch_size=1):\n",
        "        data_type = dataset_type\n",
        "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs = []\n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "\n",
        "        return imgs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"val\"\n",
        "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        self.n_batches = int(len(path) / batch_size)\n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        path = np.random.choice(path, total_samples, replace=False)\n",
        "\n",
        "        for i in range(self.n_batches-1):\n",
        "            batch = path[i*batch_size:(i+1)*batch_size]\n",
        "            imgs = []\n",
        "            attribs = []\n",
        "            for img_path in batch:\n",
        "                img = self.imread(img_path)\n",
        "\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img = np.fliplr(img)\n",
        "\n",
        "                imgs.append(img)\n",
        "\n",
        "                # get attributes\n",
        "\n",
        "                img_attribs = [(val + 1) // 2 for val in self.complete_df.loc[self.complete_df['image_id'] == os.path.basename(img_path)].filter(items=self.features).to_numpy()[0][1:].tolist()]\n",
        "\n",
        "                attribs.append(np.array(img_attribs))\n",
        "\n",
        "            imgs = np.array(imgs)/127.5 - 1.\n",
        "            attribs = np.array(attribs)\n",
        "\n",
        "            yield imgs, attribs\n",
        "\n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode='RGB').astype(np.float)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwT3pToianO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_encoder(img_shape, num_filters=64, kernel_size=4, strides=2):\n",
        "  def build_conv(x, num_filters, kernel_size, strides):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "  img = Input(shape=img_shape)\n",
        "  x = build_conv(img, num_filters, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 2, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 4, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 8, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 16, kernel_size, strides)\n",
        "\n",
        "  return Model(img, x)\n",
        "\n",
        "def build_embedding(img, label, input_shape, attr_size):\n",
        "  label_embedding = Embedding(2, np.prod(input_shape), input_length=attr_size)(label)\n",
        "  label_embedding = Reshape(input_shape[:-1] + (attr_size * input_shape[-1], ))(label_embedding)\n",
        "  emb_img = Concatenate(axis=-1)([img, label_embedding])\n",
        "  return emb_img\n",
        "\n",
        "def build_decoder(latent_space_shape, attr_size, num_filters=64, kernel_size=4, strides=1):\n",
        "  def build_deconv(x, num_filters, kernel_size, strides):\n",
        "    x = UpSampling2D(size=2)(x)\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "  img = Input(shape=latent_space_shape)\n",
        "  label = Input(shape=(attr_size, ), dtype='int32')\n",
        "\n",
        "  emb_img = build_embedding(img, label, latent_space_shape, attr_size)\n",
        "\n",
        "  x = build_deconv(emb_img, num_filters * 16, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 8, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 4, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 2, kernel_size=kernel_size, strides=strides)\n",
        "  x = UpSampling2D(size=2)(x)\n",
        "  x = Conv2D(3, kernel_size=kernel_size, strides=strides, padding='same', activation='tanh')(x)\n",
        "\n",
        "  return Model([img, label], x)\n",
        "\n",
        "def build_convnet(img, num_filters=64, kernel_size=4, strides=2):\n",
        "  def build_conv(x, num_filters, kernel_size, strides):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = InstanceNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "  \n",
        "  x = build_conv(img, num_filters, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 2, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 4, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 8, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 16, kernel_size, strides)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024)(x)\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def build_dc(img_shape, attr_size, optimizer): # NOTE: we ignore inputting original image to discriminator head. why? cause im not sure if its important\n",
        "  img = Input(shape=img_shape)\n",
        "  label = Input(shape=(attr_size, ), dtype='int32')\n",
        "\n",
        "  emb_img = build_embedding(img, label, img_shape, attr_size)\n",
        "  x = build_convnet(emb_img)\n",
        "  disc_output = Dense(1)(x)\n",
        "  classif_output = Dense(attr_size, activation='sigmoid')(x)\n",
        "\n",
        "  dc = Model([img, label], [disc_output, classif_output])\n",
        "\n",
        "  dc.compile(loss=['binary_crossentropy', 'binary_crossentropy'], loss_weights=[1, 1], optimizer=optimizer)\n",
        "\n",
        "  return dc\n",
        "\n",
        "def build_combined_generator(img_shape, attr_size, genc, gdec, dc, optimizer):\n",
        "  dc.trainable = False\n",
        "\n",
        "  x_a = Input(shape=img_shape) # original image\n",
        "  a = Input(shape=(attr_size, )) # original attr\n",
        "  b = Input(shape=(attr_size, )) # requested attr\n",
        "  \n",
        "  z = genc(x_a) # latent space representation of original image\n",
        "  x_b_hat = gdec([z, b]) # image with requested attr\n",
        "\n",
        "  valid, b_hat = dc([x_b_hat, b]) # guess real or fake and if the requested features \n",
        "\n",
        "  x_a_hat = gdec([z, a]) # reconstr\n",
        "\n",
        "  combined = Model(\n",
        "      inputs=[x_a, a, b],\n",
        "      outputs=[b_hat, valid, x_a_hat]\n",
        "  )\n",
        "\n",
        "  combined.compile(loss=['binary_crossentropy', 'binary_crossentropy', 'mae'], loss_weights=[10, 1, 100], optimizer=optimizer)\n",
        "\n",
        "  return combined"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh62XJlhZSTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle(elems):\n",
        "  new_elems = elems.copy()\n",
        "  np.random.shuffle(new_elems)\n",
        "  return new_elems\n",
        "\n",
        "def random_attrs(attr_size, count):\n",
        "  return np.random.randint(0, 2, size=(count, attr_size))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1S3__xyoSCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_dc_step(batch_size, batch_gen, genc, gdec, dc):\n",
        "  imgs, attrs = next(batch_gen)\n",
        "  new_attrs = random_attrs(attrs[0].size, batch_size)\n",
        "\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  x_a = imgs\n",
        "  a = attrs\n",
        "  b = new_attrs\n",
        "\n",
        "  z = genc.predict(x_a)\n",
        "  x_b_hat = gdec.predict([z, b])\n",
        "\n",
        "  dc_real_history = dc.fit([x_a, a], [real, a])\n",
        "  dc_fake_history = dc.fit([x_b_hat, b], [fake, b])\n",
        "\n",
        "\n",
        "def train_encdec_step(batch_size, batch_gen, combined):\n",
        "  imgs, attrs = next(batch_gen)\n",
        "  new_attrs = random_attrs(attrs[0].size, batch_size)\n",
        "\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  x_a = imgs\n",
        "  a = attrs\n",
        "  b = new_attrs\n",
        "\n",
        "  g_real_loss = combined.fit([x_a, a, b], [b, real, x_a])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSbgXa0M9aWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HairyGan(): # based on AttGan\n",
        "  def __init__(self):\n",
        "\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.img_channels = 3\n",
        "\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
        "    \n",
        "    patch = int(self.img_rows / 2**4)\n",
        "    self.disc_out = (patch, patch, 1) # output shape of discriminator\n",
        "\n",
        "    self.data_loader = DataLoader(dataset_name='celeba-dataset', img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "    self.optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "  def train(self, num_epochs, batch_size, sample_interval):\n",
        "    # set up data loader\n",
        "    dl = DataLoader('celeba-dataset', self.img_shape)\n",
        "    gen = dl.load_batch(batch_size=batch_size)\n",
        "    for i, elem in enumerate(gen):\n",
        "      break\n",
        "\n",
        "    # get data\n",
        "    # imgs, attrs = next(gen)\n",
        "    # new_attrs = random_attrs(attr_size, attrs.shape[0])\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'enc.hdf5')):\n",
        "      enc = load_model(os.path.join(project_path, 'enc.hdf5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "    else:\n",
        "      enc = build_encoder(self.img_shape)\n",
        "    \n",
        "    # encodings = enc.predict(imgs)\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'dec.hdf5')):\n",
        "      dec = load_model(os.path.join(project_path, 'dec.hdf5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "    else:\n",
        "      dec = build_decoder((4, 4, 1024), dl.num_attrs)\n",
        "\n",
        "    # reconstrs = dec.predict([encodings, attrs])\n",
        "\n",
        "    # new_imgs = dec.predict([encodings, new_attrs])\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'dc.hdf5')):\n",
        "      dc = load_model(os.path.join(project_path, 'dc.hdf5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "    else:\n",
        "      dc = build_dc(self.img_shape, dl.num_attrs, self.optimizer)\n",
        "\n",
        "    combined = build_combined_generator(self.img_shape, dl.num_attrs, enc, dec, dc, self.optimizer)\n",
        "    # combined.predict([imgs, attrs, new_attrs])    \n",
        "\n",
        "    self._train(num_epochs=100, num_batches=dl.n_batches, batch_size=batch_size, batch_gen=gen, genc=enc, gdec=dec, dc=dc, combined=combined, sample_interval=sample_interval)\n",
        "\n",
        "  def _train(self, num_epochs, num_batches, batch_size, batch_gen, genc, gdec, dc, combined, sample_interval):\n",
        "    steps_per_epoch = num_batches\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      for step in tqdm(range(steps_per_epoch), desc=f'Train {epoch} / {num_epochs}', total=steps_per_epoch):\n",
        "        train_dc_step(batch_size, batch_gen, genc, gdec, dc)\n",
        "        train_encdec_step(batch_size, batch_gen, combined)\n",
        "\n",
        "        if (step + 1) % sample_interval == 0:\n",
        "          # self.sample_images(epoch, step)\n",
        "          \n",
        "          # save models\n",
        "          genc.save('genc.h5')\n",
        "          shutil.copy('genc.h5', os.path.join(project_path, 'genc.h5'))\n",
        "\n",
        "          gdec.save('gdec.h5')\n",
        "          shutil.copy('gdec.h5', os.path.join(project_path, 'gdec.h5'))\n",
        "\n",
        "          dc.save('dc.h5')\n",
        "          shutil.copy('dc.h5', os.path.join(project_path, 'dc.h5'))\n",
        "\n",
        "          combined.save('combined.h5')\n",
        "          shutil.copy('combined.h5', os.path.join(project_path, 'combined.h5'))\n",
        "\n",
        "\n",
        "  ## TODO: re-implement this method without domains\n",
        "  def sample_images(self, epoch, batch_i):\n",
        "    print(f'Epoch: {epoch} with batch: {batch_i}')\n",
        "    rows, cols = 2, 3\n",
        "\n",
        "    imgs_A = self.data_loader.load_data(batch_size=1, is_testing=True)\n",
        "    imgs_B = self.data_loader.load_data(domain='B', batch_size=1, is_testing=True)\n",
        "\n",
        "    fake_A = self.g_BA.predict(imgs_B)\n",
        "    fake_B = self.g_AB.predict(imgs_A)\n",
        "\n",
        "    reconstr_A = self.g_BA.predict(fake_B)\n",
        "    reconstr_B = self.g_AB.predict(fake_A)\n",
        "\n",
        "    gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
        "\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    titles = ['Original', 'Translated', 'Reconstructed']\n",
        "    fig, axes = plt.subplots(rows, cols)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for i in range(rows):\n",
        "      for j in range(cols):\n",
        "        axes[i, j].imshow(gen_imgs[count])\n",
        "        axes[i, j].set_title(titles[j])\n",
        "        axes[i, j].axis('off')\n",
        "        count += 1\n",
        "\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCeFNls66FAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "abdd857e-2cb0-4096-a0fb-01d080c7729f"
      },
      "source": [
        "project_path = '/content/drive/My Drive/hairy_gan'\n",
        "gan = HairyGan()\n",
        "gan.train(num_epochs=100, batch_size=32, sample_interval=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "\n",
            "\n",
            "\n",
            "Train 0 / 100:   0%|          | 0/81385 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 421ms/step - loss: 16.2485 - dense_29_loss: 15.4249 - dense_30_loss: 0.8235\n",
            "Epoch 1/1\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 14.2979 - dense_29_loss: 8.4661 - dense_30_loss: 5.8318\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb-CKtN1I-i0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.g_AB = load_model('/content/drive/My Drive/hairy_gan/g_AB.hdf5', custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "gan.g_BA = load_model('/content/drive/My Drive/hairy_gan/g_BA.hdf5', custom_objects={'InstanceNormalization': InstanceNormalization})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw-8yJewVOxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.sample_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S1FG5p2Z0D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}