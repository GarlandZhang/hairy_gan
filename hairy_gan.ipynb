{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hairy_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PFgBE9Rkd8fOWpAi2lsgE1RrQYJKfdKa",
      "authorship_tag": "ABX9TyP0FIIcI/eLn6onQzx987Jp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/hairy_gan/blob/master/hairy_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb_cPA4QnnNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "if not os.path.exists('kaggle.json'):\n",
        "  shutil.copy('/content/drive/My Drive/hairy_gan/kaggle.json', 'kaggle.json')\n",
        "  # !pip install -q kaggle\n",
        "  # files.upload()\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !kaggle datasets download -d jessicali9530/celeba-dataset --force\n",
        "  !unzip celeba-dataset.zip\n",
        "  !mv img_align_celeba celeba-dataset\n",
        "  !mv list_eval_partition.csv celeba-dataset/list_eval_partition.csv\n",
        "  !mv list_landmarks_align_celeba.csv celeba-dataset/list_landmarks_align_celeba.csv\n",
        "  !mv list_attr_celeba.csv celeba-dataset/list_attr_celeba.csv\n",
        "  !mv list_bbox_celeba.csv celeba-dataset/list_bbox_celeba.csv\n",
        "\n",
        "  !mkdir celeba-dataset/train\n",
        "  !mkdir celeba-dataset/validation\n",
        "  !mkdir celeba-dataset/test\n",
        "\n",
        "  partitions_df = pd.read_csv('celeba-dataset/list_eval_partition.csv') # 0 => train, 1 => validation, 2 => test\n",
        "  for i, set_name in enumerate(['train', 'validation', 'test']):\n",
        "    set_ids_df = partitions_df.loc[partitions_df['partition'] == i]['image_id']\n",
        "    set_ids = set_ids_df.tolist()\n",
        "    for id in set_ids:\n",
        "      shutil.copy(os.path.join('celeba-dataset/img_align_celeba', id), os.path.join('celeba-dataset', f'{set_name}', id))\n",
        "\n",
        "  !git clone https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && cd keras-contrib \\\n",
        "    && pip install git+https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && python convert_to_tf_keras.py \\\n",
        "    && USE_TF_KERAS=1 python setup.py install\n",
        "\n",
        "  !pip install scipy==1.1.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_tQXJCU83oV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "56feb329-5a6a-46e3-d9e7-38b0a292fcce"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Embedding\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model, save_model\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.backend import set_session, clear_session\n",
        "# from tensorflow.python.keras.models import load_model\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "tf.compat.v1.disable_v2_behavior()\n",
        "# tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpW0Uqm7v6y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, dataset_name, img_res):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "        self.complete_df = pd.read_csv('celeba-dataset/list_attr_celeba.csv')\n",
        "        self.features = ['Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Bushy_Eyebrows', 'Eyeglasses', 'Gender', 'Mouth_Open', 'Mustache', 'No_Beard', 'Pale_Skin', 'Age']\n",
        "        self.num_attrs = 9 # should equal to length of self.features\n",
        "\n",
        "    def load_data(self, dataset_type, batch_size=1, is_testing=False):\n",
        "        data_type = dataset_type\n",
        "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs = []\n",
        "        attribs = []\n",
        "        \n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "            # get attributes\n",
        "\n",
        "            img_attribs = [(val + 1) // 2 for val in self.complete_df.loc[self.complete_df['image_id'] == os.path.basename(img_path)].filter(items=self.features).to_numpy()[0][1:].tolist()]\n",
        "\n",
        "            attribs.append(np.array(img_attribs))\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "        attribs = np.array(attribs)\n",
        "\n",
        "        return imgs, attribs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"val\"\n",
        "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        self.n_batches = int(len(path) / batch_size)\n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        path = np.random.choice(path, total_samples, replace=False)\n",
        "\n",
        "        for i in range(self.n_batches-1):\n",
        "            batch = path[i*batch_size:(i+1)*batch_size]\n",
        "            imgs = []\n",
        "            attribs = []\n",
        "            for img_path in batch:\n",
        "                img = self.imread(img_path)\n",
        "\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img = np.fliplr(img)\n",
        "\n",
        "                imgs.append(img)\n",
        "\n",
        "                # get attributes\n",
        "\n",
        "                img_attribs = [(val + 1) // 2 for val in self.complete_df.loc[self.complete_df['image_id'] == os.path.basename(img_path)].filter(items=self.features).to_numpy()[0][1:].tolist()]\n",
        "\n",
        "                attribs.append(np.array(img_attribs))\n",
        "\n",
        "            imgs = np.array(imgs)/127.5 - 1.\n",
        "            attribs = np.array(attribs)\n",
        "\n",
        "            yield imgs, attribs\n",
        "\n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode='RGB').astype(np.float)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwT3pToianO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_encoder(img_shape, num_filters=64, kernel_size=4, strides=2):\n",
        "  def build_conv(x, num_filters, kernel_size, strides):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "  img = Input(shape=img_shape)\n",
        "  x = build_conv(img, num_filters, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 2, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 4, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 8, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 16, kernel_size, strides)\n",
        "\n",
        "  return Model(img, x)\n",
        "\n",
        "def build_embedding(img, label, input_shape, attr_size):\n",
        "  label_embedding = Embedding(2, np.prod(input_shape), input_length=attr_size)(label)\n",
        "  # style_embedding = Embedding(2, np.prod(input_shape), input_length=attr_size)(style)\n",
        "  # label_style_embedding = Add()([label_embedding, style_embedding])\n",
        "  # label_style_embedding = Reshape(input_shape[:-1] + (attr_size * input_shape[-1], ))(label_style_embedding)\n",
        "  # emb_img = Concatenate(axis=-1)([img, label_style_embedding])\n",
        "  label_embedding = Reshape(input_shape[:-1] + (attr_size * input_shape[-1], ))(label_embedding)\n",
        "  emb_img = Concatenate(axis=-1)([img, label_embedding])\n",
        "  return emb_img\n",
        "\n",
        "def build_decoder(latent_space_shape, attr_size, num_filters=64, kernel_size=4, strides=1):\n",
        "  def build_deconv(x, num_filters, kernel_size, strides):\n",
        "    x = UpSampling2D(size=2)(x)\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "  img = Input(shape=latent_space_shape)\n",
        "  label = Input(shape=(attr_size, ), dtype='int32')\n",
        "\n",
        "  emb_img = build_embedding(img, label, latent_space_shape, attr_size)\n",
        "\n",
        "  x = build_deconv(emb_img, num_filters * 16, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 8, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 4, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 2, kernel_size=kernel_size, strides=strides)\n",
        "  x = UpSampling2D(size=2)(x)\n",
        "  x = Conv2D(3, kernel_size=kernel_size, strides=strides, padding='same', activation='tanh')(x)\n",
        "\n",
        "  return Model([img, label], x)\n",
        "\n",
        "def build_convnet(img, num_filters=64, kernel_size=4, strides=2):\n",
        "  def build_conv(x, num_filters, kernel_size, strides):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = InstanceNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "  \n",
        "  x = build_conv(img, num_filters, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 2, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 4, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 8, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 16, kernel_size, strides)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024)(x)\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def build_dc(img_shape, attr_size, optimizer): # NOTE: we ignore inputting original image to discriminator head. why? cause im not sure if its important\n",
        "  img = Input(shape=img_shape)\n",
        "  label = Input(shape=(attr_size, ), dtype='int32') # I don't understand. why do we have this?\n",
        "\n",
        "  # emb_img = build_embedding(img, label, img_shape, attr_size)\n",
        "  # x = build_convnet(emb_img)\n",
        "  x = build_convnet(img)\n",
        "  disc_output = Dense(1)(x)\n",
        "  classif_output = Dense(attr_size, activation='sigmoid')(x)\n",
        "\n",
        "  dc = Model([img, label], [disc_output, classif_output])\n",
        "\n",
        "  dc.compile(loss=['binary_crossentropy', 'binary_crossentropy'], loss_weights=[1, 1], optimizer=optimizer)\n",
        "\n",
        "  return dc\n",
        "\n",
        "def build_combined_generator(img_shape, attr_size, genc, gdec, dc, optimizer):\n",
        "  dc.trainable = False\n",
        "\n",
        "  x_a = Input(shape=img_shape) # original image\n",
        "  a = Input(shape=(attr_size, )) # original attr\n",
        "  b = Input(shape=(attr_size, )) # requested attr\n",
        "  \n",
        "  z = genc(x_a) # latent space representation of original image\n",
        "  x_b_hat = gdec([z, b]) # image with requested attr\n",
        "\n",
        "  valid, b_hat = dc([x_b_hat, b]) # guess real or fake and guess the requested features \n",
        "\n",
        "  x_a_hat = gdec([z, a]) # reconstr\n",
        "\n",
        "  combined = Model(\n",
        "      inputs=[x_a, a, b],\n",
        "      outputs=[b_hat, valid, x_a_hat]\n",
        "  )\n",
        "\n",
        "  combined.compile(loss=['binary_crossentropy', 'binary_crossentropy', 'mae'], loss_weights=[10, 1, 100], optimizer=optimizer)\n",
        "\n",
        "  return combined"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh62XJlhZSTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle(elems):\n",
        "  new_elems = elems.copy()\n",
        "  np.random.shuffle(new_elems)\n",
        "  return new_elems\n",
        "\n",
        "def random_attrs(attr_size, count):\n",
        "  return np.random.randint(0, 2, size=(count, attr_size))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1S3__xyoSCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_dc_step(batch_size, batch_gen, genc, gdec, dc):\n",
        "  imgs, attrs = next(batch_gen)\n",
        "  new_attrs = random_attrs(attrs[0].size, batch_size)\n",
        "\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  x_a = imgs\n",
        "  a = attrs\n",
        "  b = new_attrs\n",
        "\n",
        "  z = genc.predict(x_a)\n",
        "  x_b_hat = gdec.predict([z, b])\n",
        "\n",
        "  dc_real_history = dc.fit([x_a, a], [real, a])\n",
        "  dc_fake_history = dc.fit([x_b_hat, b], [fake, b])\n",
        "\n",
        "\n",
        "def train_encdec_step(batch_size, batch_gen, combined):\n",
        "  imgs, attrs = next(batch_gen)\n",
        "  new_attrs = random_attrs(attrs[0].size, batch_size)\n",
        "\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  x_a = imgs\n",
        "  a = attrs\n",
        "  b = new_attrs\n",
        "\n",
        "  g_real_loss = combined.fit([x_a, a, b], [b, fake, x_a])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSbgXa0M9aWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HairyGan(): # based on AttGan\n",
        "  def __init__(self):\n",
        "\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.img_channels = 3\n",
        "\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
        "    \n",
        "    patch = int(self.img_rows / 2**4)\n",
        "    self.disc_out = (patch, patch, 1) # output shape of discriminator\n",
        "\n",
        "    self.dl = DataLoader(dataset_name='celeba-dataset', img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "    self.optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'enc.h5')):\n",
        "      self.enc = load_model(os.path.join(project_path, 'enc.h5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "    else:\n",
        "      self.enc = build_encoder(self.img_shape)\n",
        "    \n",
        "    if os.path.exists(os.path.join(project_path, 'dec.h5')):\n",
        "      self.dec = load_model(os.path.join(project_path, 'dec.h5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "    else:\n",
        "      self.dec = build_decoder((4, 4, 1024), self.dl.num_attrs)\n",
        "\n",
        "    self.dc = build_dc(self.img_shape, self.dl.num_attrs, self.optimizer)\n",
        "    \n",
        "    if os.path.exists(os.path.join(project_path, 'dc.weights')):\n",
        "      self.dc.load_weights(os.path.join(project_path, 'dc.weights'))\n",
        "\n",
        "    self.combined = build_combined_generator(self.img_shape, self.dl.num_attrs, self.enc, self.dec, self.dc, self.optimizer)   \n",
        "\n",
        "  def train(self, num_epochs, batch_size, sample_interval):\n",
        "    # set up data loader\n",
        "    gen = self.dl.load_batch(batch_size=batch_size)\n",
        "    for i, elem in enumerate(gen):\n",
        "      break\n",
        "\n",
        "    self._train(num_epochs=100, num_batches=self.dl.n_batches, batch_size=batch_size, batch_gen=gen, sample_interval=sample_interval)\n",
        "\n",
        "  def _train(self, num_epochs, num_batches, batch_size, batch_gen, sample_interval):\n",
        "    steps_per_epoch = num_batches\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      for step in tqdm(range(steps_per_epoch), desc=f'Train {epoch} / {num_epochs}', total=steps_per_epoch):\n",
        "        train_dc_step(batch_size, batch_gen, self.enc, self.dec, self.dc)\n",
        "        train_encdec_step(batch_size, batch_gen, self.combined)\n",
        "\n",
        "        if (step + 1) % sample_interval == 0:\n",
        "          self.sample_images(epoch, step)\n",
        "          \n",
        "          # save models\n",
        "          save_model(self.enc, 'enc.h5')\n",
        "          shutil.copy('enc.h5', os.path.join(project_path, 'enc.h5'))\n",
        "\n",
        "          save_model(self.dec, 'dec.h5')\n",
        "          shutil.copy('dec.h5', os.path.join(project_path, 'dec.h5'))\n",
        "\n",
        "          self.dc.save_weights('dc.weights')\n",
        "          shutil.copy('dc.weights', os.path.join(project_path, 'dc.weights'))\n",
        "\n",
        "          self.combined.save_weights('combined.weights')\n",
        "          shutil.copy('combined.weights', os.path.join(project_path, 'combined.weights'))\n",
        "\n",
        "\n",
        "  def sample_images(self, epoch, batch_i):\n",
        "    print(f'Epoch: {epoch} with batch: {batch_i}')\n",
        "    rows, cols = 2, 3\n",
        "\n",
        "    imgs, attrs = self.dl.load_data('test', batch_size=2, is_testing=True)\n",
        "\n",
        "    new_attrs = random_attrs(attrs[0].size, attrs.shape[0])\n",
        "\n",
        "    encodings = self.enc.predict(imgs)\n",
        "\n",
        "    reconstrs = self.dec.predict([encodings, attrs])\n",
        "\n",
        "    new_imgs = self.dec.predict([encodings, new_attrs])\n",
        "    # combined.predict([imgs, attrs, new_attrs]) \n",
        "\n",
        "    gen_imgs = np.array([imgs[0], new_imgs[0], reconstrs[0], imgs[1], new_imgs[1], reconstrs[1]])\n",
        "\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    titles = ['Original', 'Translated', 'Reconstructed']\n",
        "    fig, axes = plt.subplots(rows, cols)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for i in range(rows):\n",
        "      for j in range(cols):\n",
        "        axes[i, j].imshow(gen_imgs[count])\n",
        "        axes[i, j].set_title(titles[j])\n",
        "        axes[i, j].axis('off')\n",
        "        count += 1\n",
        "\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCeFNls66FAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a2db6fb1-b974-48d3-fdcd-7816f441a6a4"
      },
      "source": [
        "project_path = '/content/drive/My Drive/hairy_gan'\n",
        "gan = HairyGan()\n",
        "# gan.train(num_epochs=100, batch_size=32, sample_interval=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYxuaTSDe1nj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "be38b64a-b6bc-4f83-f46b-374d1541db36"
      },
      "source": [
        "gan.train(num_epochs=100, batch_size=32, sample_interval=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "Train 0 / 100:   0%|          | 0/5086 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "32/32 [==============================] - 5s 143ms/step - loss: 15.8426 - dense_2_loss: 15.4249 - dense_3_loss: 0.4176\n",
            "Epoch 1/1\n",
            "32/32 [==============================] - 4s 112ms/step - loss: 0.9307 - dense_2_loss: 0.0000e+00 - dense_3_loss: 0.9307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "963yDk9Qif1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}