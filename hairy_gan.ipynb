{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hairy_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PFgBE9Rkd8fOWpAi2lsgE1RrQYJKfdKa",
      "authorship_tag": "ABX9TyMxVPpQu/F07L7EaJFoJEzA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/hairy_gan/blob/master/hairy_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb_cPA4QnnNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "if not os.path.exists('kaggle.json'):\n",
        "  shutil.copy('/content/drive/My Drive/hairy_gan/kaggle.json', 'kaggle.json')\n",
        "  # !pip install -q kaggle\n",
        "  # files.upload()\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !kaggle datasets download -d jessicali9530/celeba-dataset --force\n",
        "  !unzip celeba-dataset.zip\n",
        "  !mv img_align_celeba celeba-dataset\n",
        "  !mv list_eval_partition.csv celeba-dataset/list_eval_partition.csv\n",
        "  !mv list_landmarks_align_celeba.csv celeba-dataset/list_landmarks_align_celeba.csv\n",
        "  !mv list_attr_celeba.csv celeba-dataset/list_attr_celeba.csv\n",
        "  !mv list_bbox_celeba.csv celeba-dataset/list_bbox_celeba.csv\n",
        "\n",
        "  !mkdir celeba-dataset/train\n",
        "  !mkdir celeba-dataset/validation\n",
        "  !mkdir celeba-dataset/test\n",
        "\n",
        "  partitions_df = pd.read_csv('celeba-dataset/list_eval_partition.csv') # 0 => train, 1 => validation, 2 => test\n",
        "  for i, set_name in enumerate(['train', 'validation', 'test']):\n",
        "    set_ids_df = partitions_df.loc[partitions_df['partition'] == i]['image_id']\n",
        "    set_ids = set_ids_df.tolist()\n",
        "    for id in set_ids:\n",
        "      shutil.copy(os.path.join('celeba-dataset/img_align_celeba', id), os.path.join('celeba-dataset', f'{set_name}', id))\n",
        "\n",
        "  !git clone https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && cd keras-contrib \\\n",
        "    && pip install git+https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && python convert_to_tf_keras.py \\\n",
        "    && USE_TF_KERAS=1 python setup.py install\n",
        "\n",
        "  !pip install scipy==1.1.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_tQXJCU83oV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "56feb329-5a6a-46e3-d9e7-38b0a292fcce"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Embedding\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model, save_model\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.backend import set_session, clear_session\n",
        "# from tensorflow.python.keras.models import load_model\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "tf.compat.v1.disable_v2_behavior()\n",
        "# tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpW0Uqm7v6y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, dataset_name, img_res):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "        self.complete_df = pd.read_csv('celeba-dataset/list_attr_celeba.csv')\n",
        "        self.features = ['Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Bushy_Eyebrows', 'Eyeglasses', 'Gender', 'Mouth_Open', 'Mustache', 'No_Beard', 'Pale_Skin', 'Age']\n",
        "        self.num_attrs = 9 # should equal to length of self.features\n",
        "\n",
        "    def load_data(self, dataset_type, batch_size=1, is_testing=False):\n",
        "        data_type = dataset_type\n",
        "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs = []\n",
        "        attribs = []\n",
        "        \n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "            # get attributes\n",
        "\n",
        "            img_attribs = [(val + 1) // 2 for val in self.complete_df.loc[self.complete_df['image_id'] == os.path.basename(img_path)].filter(items=self.features).to_numpy()[0][1:].tolist()]\n",
        "\n",
        "            attribs.append(np.array(img_attribs))\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "        attribs = np.array(attribs)\n",
        "\n",
        "        return imgs, attribs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"val\"\n",
        "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        self.n_batches = int(len(path) / batch_size)\n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        path = np.random.choice(path, total_samples, replace=False)\n",
        "\n",
        "        for i in range(self.n_batches-1):\n",
        "            batch = path[i*batch_size:(i+1)*batch_size]\n",
        "            imgs = []\n",
        "            attribs = []\n",
        "            for img_path in batch:\n",
        "                img = self.imread(img_path)\n",
        "\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img = np.fliplr(img)\n",
        "\n",
        "                imgs.append(img)\n",
        "\n",
        "                # get attributes\n",
        "\n",
        "                img_attribs = [(val + 1) // 2 for val in self.complete_df.loc[self.complete_df['image_id'] == os.path.basename(img_path)].filter(items=self.features).to_numpy()[0][1:].tolist()]\n",
        "\n",
        "                attribs.append(np.array(img_attribs))\n",
        "\n",
        "            imgs = np.array(imgs)/127.5 - 1.\n",
        "            attribs = np.array(attribs)\n",
        "\n",
        "            yield imgs, attribs\n",
        "\n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode='RGB').astype(np.float)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwT3pToianO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_encoder(img_shape, num_filters=64, kernel_size=4, strides=2):\n",
        "  def build_conv(x, num_filters, kernel_size, strides):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "  img = Input(shape=img_shape)\n",
        "  x = build_conv(img, num_filters, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 2, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 4, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 8, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 16, kernel_size, strides)\n",
        "  x.name = 'encoder_output'\n",
        "\n",
        "  model = Model(img, x, name='encoder')\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def build_embedding(img, label, input_shape, attr_size):\n",
        "  label_embedding = Embedding(2, np.prod(input_shape), input_length=attr_size)(label)\n",
        "  # style_embedding = Embedding(2, np.prod(input_shape), input_length=attr_size)(style)\n",
        "  # label_style_embedding = Add()([label_embedding, style_embedding])\n",
        "  # label_style_embedding = Reshape(input_shape[:-1] + (attr_size * input_shape[-1], ))(label_style_embedding)\n",
        "  # emb_img = Concatenate(axis=-1)([img, label_style_embedding])\n",
        "  label_embedding = Reshape(input_shape[:-1] + (attr_size * input_shape[-1], ))(label_embedding)\n",
        "  emb_img = Concatenate(axis=-1)([img, label_embedding])\n",
        "  return emb_img\n",
        "\n",
        "def build_decoder(latent_space_shape, attr_size, num_filters=64, kernel_size=4, strides=1):\n",
        "  def build_deconv(x, num_filters, kernel_size, strides):\n",
        "    x = UpSampling2D(size=2)(x)\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "  img = Input(shape=latent_space_shape)\n",
        "  label = Input(shape=(attr_size, ), dtype='int32')\n",
        "\n",
        "  emb_img = build_embedding(img, label, latent_space_shape, attr_size)\n",
        "\n",
        "  x = build_deconv(emb_img, num_filters * 16, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 8, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 4, kernel_size=kernel_size, strides=strides)\n",
        "  x = build_deconv(x, num_filters * 2, kernel_size=kernel_size, strides=strides)\n",
        "  x = UpSampling2D(size=2)(x)\n",
        "  x = Conv2D(3, kernel_size=kernel_size, strides=strides, padding='same', activation='tanh')(x)\n",
        "  x.name = 'decoder_output'\n",
        "\n",
        "  model = Model([img, label], x, name='decoder')\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def build_convnet(img, num_filters=64, kernel_size=4, strides=2):\n",
        "  def build_conv(x, num_filters, kernel_size, strides):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = InstanceNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x\n",
        "  \n",
        "  x = build_conv(img, num_filters, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 2, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 4, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 8, kernel_size, strides)\n",
        "  x = build_conv(x, num_filters * 16, kernel_size, strides)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024)(x)\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def build_dc(img_shape, attr_size, optimizer): # NOTE: we ignore inputting original image to discriminator head. why? cause im not sure if its important\n",
        "  img = Input(shape=img_shape)\n",
        "  label = Input(shape=(attr_size, ), dtype='int32') # I don't understand. why do we have this?\n",
        "\n",
        "  # emb_img = build_embedding(img, label, img_shape, attr_size)\n",
        "  # x = build_convnet(emb_img)\n",
        "  x = build_convnet(img)\n",
        "  disc_output = Dense(1, name='disc_output')(x)\n",
        "  classif_output = Dense(attr_size, activation='sigmoid', name='classif_output')(x)\n",
        "\n",
        "  dc = Model([img, label], [disc_output, classif_output], name='dc')\n",
        "\n",
        "  dc.compile(loss=['binary_crossentropy', 'binary_crossentropy'], loss_weights=[1, 1], optimizer=optimizer)\n",
        "\n",
        "  dc.summary()\n",
        "\n",
        "  return dc\n",
        "\n",
        "def build_combined_generator(img_shape, attr_size, genc, gdec, dc, optimizer):\n",
        "  dc.trainable = False\n",
        "\n",
        "  x_a = Input(shape=img_shape) # original image\n",
        "  a = Input(shape=(attr_size, )) # original attr\n",
        "  b = Input(shape=(attr_size, )) # requested attr\n",
        "  \n",
        "  z = genc(x_a) # latent space representation of original image\n",
        "  x_b_hat = gdec([z, b]) # image with requested attr\n",
        "\n",
        "  valid, b_hat = dc([x_b_hat, b]) # guess real or fake and guess the requested features \n",
        "\n",
        "  x_a_hat = gdec([z, a]) # reconstr\n",
        "\n",
        "  combined = Model(\n",
        "      inputs=[x_a, a, b],\n",
        "      outputs=[b_hat, valid, x_a_hat],\n",
        "      name='combined'\n",
        "  )\n",
        "\n",
        "  combined.compile(loss=['binary_crossentropy', 'binary_crossentropy', 'mae'], loss_weights=[10, 1, 100], optimizer=optimizer)\n",
        "\n",
        "  combined.summary()\n",
        "\n",
        "  return combined"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh62XJlhZSTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle(elems):\n",
        "  new_elems = elems.copy()\n",
        "  np.random.shuffle(new_elems)\n",
        "  return new_elems\n",
        "\n",
        "def random_attrs(attr_size, count):\n",
        "  return np.random.randint(0, 2, size=(count, attr_size))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1S3__xyoSCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_dc_step(batch_size, batch_gen, genc, gdec, dc):\n",
        "  imgs, attrs = next(batch_gen)\n",
        "  new_attrs = random_attrs(attrs[0].size, batch_size)\n",
        "\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  x_a = imgs\n",
        "  a = attrs\n",
        "  b = new_attrs\n",
        "\n",
        "  z = genc.predict(x_a)\n",
        "  x_b_hat = gdec.predict([z, b])\n",
        "\n",
        "  dc_real_history = dc.fit([x_a, a], [real, a])\n",
        "  dc_fake_history = dc.fit([x_b_hat, b], [fake, b])\n",
        "\n",
        "  return dc_real_history, dc_fake_history\n",
        "\n",
        "def train_encdec_step(batch_size, batch_gen, combined):\n",
        "  imgs, attrs = next(batch_gen)\n",
        "  new_attrs = random_attrs(attrs[0].size, batch_size)\n",
        "\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  x_a = imgs\n",
        "  a = attrs\n",
        "  b = new_attrs\n",
        "\n",
        "  g_real_history = combined.fit([x_a, a, b], [b, fake, x_a])\n",
        "\n",
        "  return g_real_history"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSbgXa0M9aWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HairyGan(): # based on AttGan\n",
        "  def __init__(self):\n",
        "\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.img_channels = 3\n",
        "\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
        "    \n",
        "    patch = int(self.img_rows / 2**4)\n",
        "    self.disc_out = (patch, patch, 1) # output shape of discriminator\n",
        "\n",
        "    self.dl = DataLoader(dataset_name='celeba-dataset', img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "    self.optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "    if os.path.exists(os.path.join(project_path, 'enc.h5')):\n",
        "      self.enc = load_model(os.path.join(project_path, 'enc.h5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "    else:\n",
        "      self.enc = build_encoder(self.img_shape)\n",
        "    \n",
        "    if os.path.exists(os.path.join(project_path, 'dec.h5')):\n",
        "      self.dec = load_model(os.path.join(project_path, 'dec.h5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "    else:\n",
        "      self.dec = build_decoder((4, 4, 1024), self.dl.num_attrs)\n",
        "\n",
        "    self.dc = build_dc(self.img_shape, self.dl.num_attrs, self.optimizer)\n",
        "    \n",
        "    if os.path.exists(os.path.join(project_path, 'dc.weights')):\n",
        "      self.dc.load_weights(os.path.join(project_path, 'dc.weights'))\n",
        "\n",
        "    self.combined = build_combined_generator(self.img_shape, self.dl.num_attrs, self.enc, self.dec, self.dc, self.optimizer)   \n",
        "\n",
        "  def train(self, num_epochs, batch_size, sample_interval):\n",
        "    # set up data loader\n",
        "    gen = self.dl.load_batch(batch_size=batch_size)\n",
        "    for i, elem in enumerate(gen):\n",
        "      break\n",
        "\n",
        "    self._train(num_epochs=100, num_batches=self.dl.n_batches, batch_size=batch_size, batch_gen=gen, sample_interval=sample_interval)\n",
        "\n",
        "  def _train(self, num_epochs, num_batches, batch_size, batch_gen, sample_interval):\n",
        "    steps_per_epoch = num_batches\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      for step in tqdm(range(steps_per_epoch), desc=f'Train {epoch} / {num_epochs}', total=steps_per_epoch):\n",
        "        dc_real_history, dc_fake_history = train_dc_step(batch_size, batch_gen, self.enc, self.dec, self.dc)\n",
        "        g_real_history = train_encdec_step(batch_size, batch_gen, self.combined)\n",
        "\n",
        "        if (step + 1) % sample_interval == 0:\n",
        "          self.sample_images(epoch, step)\n",
        "          \n",
        "          # save models\n",
        "          save_model(self.enc, 'enc.h5')\n",
        "          shutil.copy('enc.h5', os.path.join(project_path, 'enc.h5'))\n",
        "\n",
        "          save_model(self.dec, 'dec.h5')\n",
        "          shutil.copy('dec.h5', os.path.join(project_path, 'dec.h5'))\n",
        "\n",
        "          self.dc.save_weights('dc.weights')\n",
        "          shutil.copy('dc.weights', os.path.join(project_path, 'dc.weights'))\n",
        "\n",
        "          self.combined.save_weights('combined.weights')\n",
        "          shutil.copy('combined.weights', os.path.join(project_path, 'combined.weights'))\n",
        "\n",
        "          # visualize loss/accuracy\n",
        "\n",
        "\n",
        "\n",
        "  def sample_images(self, epoch, batch_i):\n",
        "    print(f'Epoch: {epoch} with batch: {batch_i}')\n",
        "    rows, cols = 2, 3\n",
        "\n",
        "    imgs, attrs = self.dl.load_data('test', batch_size=2, is_testing=True)\n",
        "\n",
        "    new_attrs = random_attrs(attrs[0].size, attrs.shape[0])\n",
        "\n",
        "    encodings = self.enc.predict(imgs)\n",
        "\n",
        "    reconstrs = self.dec.predict([encodings, attrs])\n",
        "\n",
        "    new_imgs = self.dec.predict([encodings, new_attrs])\n",
        "    # combined.predict([imgs, attrs, new_attrs]) \n",
        "\n",
        "    gen_imgs = np.array([imgs[0], new_imgs[0], reconstrs[0], imgs[1], new_imgs[1], reconstrs[1]])\n",
        "\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    titles = ['Original', 'Translated', 'Reconstructed']\n",
        "    fig, axes = plt.subplots(rows, cols)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for i in range(rows):\n",
        "      for j in range(cols):\n",
        "        axes[i, j].imshow(gen_imgs[count])\n",
        "        axes[i, j].set_title(titles[j])\n",
        "        axes[i, j].axis('off')\n",
        "        count += 1\n",
        "\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCeFNls66FAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c9092ff-3ae1-4dd8-fc1f-3f4d3c66d5b3"
      },
      "source": [
        "project_path = '/content/drive/My Drive/hairy_gan'\n",
        "gan = HairyGan()\n",
        "# gan.train(num_epochs=100, batch_size=32, sample_interval=100)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"dc\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 64, 64, 64)   3136        input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_19 (Inst (None, 64, 64, 64)   2           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 64, 64, 64)   0           instance_normalization_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 128)  131200      leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_20 (Inst (None, 32, 32, 128)  2           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, 32, 32, 128)  0           instance_normalization_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 256)  524544      leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_21 (Inst (None, 16, 16, 256)  2           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, 16, 16, 256)  0           instance_normalization_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 512)    2097664     leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_22 (Inst (None, 8, 8, 512)    2           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, 8, 8, 512)    0           instance_normalization_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 1024)   8389632     leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_23 (Inst (None, 4, 4, 1024)   2           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, 4, 4, 1024)   0           instance_normalization_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 16384)        0           leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1024)         16778240    flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_24 (Inst (None, 1024)         2           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, 1024)         0           instance_normalization_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "disc_output (Dense)             (None, 1)            1025        leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "classif_output (Dense)          (None, 9)            9225        leaky_re_lu_33[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 27,934,678\n",
            "Trainable params: 27,934,678\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"combined\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 4, 4, 1024)   11154112    input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           (None, 9)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Model)                 (None, 128, 128, 3)  178830723   model_1[1][0]                    \n",
            "                                                                 input_23[0][0]                   \n",
            "                                                                 model_1[1][0]                    \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           (None, 9)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dc (Model)                      [(None, 1), (None, 9 27934678    model_2[1][0]                    \n",
            "                                                                 input_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 217,919,513\n",
            "Trainable params: 189,977,027\n",
            "Non-trainable params: 27,942,486\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "963yDk9Qif1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "132fcb60-2bfe-41de-9a00-9cdf4d7f75d7"
      },
      "source": [
        "# gan.sample_images(1, 1)\n",
        "batch_size = 2\n",
        "imgs, attrs = gan.dl.load_data('test', batch_size=batch_size, is_testing=True)\n",
        "history = gan.dc.fit([imgs, attrs], [np.ones((batch_size, 1)), attrs])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2/2 [==============================] - 1s 339ms/step - loss: 15.9388 - dense_5_loss: 15.4249 - dense_6_loss: 0.5138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3atpdZg3kLhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a5b8fde7-d928-4ff0-baf7-281dcef4eedc"
      },
      "source": [
        "history.__dict__"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': [0],\n",
              " 'history': {'dense_5_loss': [15.424949],\n",
              "  'dense_6_loss': [0.51384765],\n",
              "  'loss': [15.938796043395996]},\n",
              " 'model': <keras.engine.training.Model at 0x7f0669d9af98>,\n",
              " 'params': {'batch_size': 32,\n",
              "  'do_validation': False,\n",
              "  'epochs': 1,\n",
              "  'metrics': ['loss', 'dense_5_loss', 'dense_6_loss'],\n",
              "  'samples': 2,\n",
              "  'steps': None,\n",
              "  'verbose': 1},\n",
              " 'validation_data': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LiPqnQqm6B7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "27fbd39a-bc94-4db7-ad38-4c206180527b"
      },
      "source": [
        "gan.dc.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 64, 64, 64)   3136        input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_7 (Insta (None, 64, 64, 64)   2           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 64, 64, 64)   0           instance_normalization_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 128)  131200      leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_8 (Insta (None, 32, 32, 128)  2           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 32, 32, 128)  0           instance_normalization_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 256)  524544      leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_9 (Insta (None, 16, 16, 256)  2           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 16, 16, 256)  0           instance_normalization_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 512)    2097664     leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_10 (Inst (None, 8, 8, 512)    2           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 8, 8, 512)    0           instance_normalization_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 1024)   8389632     leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_11 (Inst (None, 4, 4, 1024)   2           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 4, 4, 1024)   0           instance_normalization_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 16384)        0           leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         16778240    flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_12 (Inst (None, 1024)         2           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 1024)         0           instance_normalization_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            1025        leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 9)            9225        leaky_re_lu_21[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 55,869,356\n",
            "Trainable params: 27,934,678\n",
            "Non-trainable params: 27,934,678\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhyg480onlG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}