{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fast_style_transfer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdiNcw5/VglmLZOhkv8n6c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/hairy_gan/blob/master/fast_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2QUooqstwlj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7546520b-6261-4b8a-8c04-4059d970a4cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzGY69RstsCh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eaa2fb41-6f74-4baf-ded5-af18e0abb7e3"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "  \n",
        "!git clone https://www.github.com/keras-team/keras-contrib.git \\\n",
        "  && cd keras-contrib \\\n",
        "  && pip install git+https://www.github.com/keras-team/keras-contrib.git \\\n",
        "  && python convert_to_tf_keras.py \\\n",
        "  && USE_TF_KERAS=1 python setup.py install\n",
        "\n",
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'keras-contrib' already exists and is not an empty directory.\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8fRD2mfejoA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9d47ac67-6e16-4987-9fb3-540451321560"
      },
      "source": [
        "import scipy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Embedding, Lambda\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model, save_model\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.backend import set_session, clear_session\n",
        "tf.compat.v1.disable_v2_behavior()\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "\n",
        "from keras.applications.vgg19 import preprocess_input, VGG19\n",
        "\n",
        "from keras.losses import mean_squared_error\n",
        "from keras import backend as k"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k62myyK0tZOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source: https://www.machinecurve.com/index.php/2020/02/10/using-constant-padding-reflection-padding-and-replication-padding-with-keras/\n",
        "from keras.layers import Layer\n",
        "\n",
        "'''\n",
        "  2D Reflection Padding\n",
        "  Attributes:\n",
        "    - padding: (padding_width, padding_height) tuple\n",
        "'''\n",
        "class ReflectionPadding2D(Layer):\n",
        "    def __init__(self, padding=(1, 1), **kwargs):\n",
        "        self.padding = tuple(padding)\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "    def compute_output_shape(self, s):\n",
        "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
        "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        w_pad,h_pad = self.padding\n",
        "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01lfdgevxLIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_layer(x, num_filters, kernel_size, stride):\n",
        "  reflection_size = kernel_size // 2\n",
        "  reflection_padding = (reflection_size, reflection_size)\n",
        "  x = ReflectionPadding2D(reflection_padding)(x)\n",
        "  x = Conv2D(filters=num_filters, kernel_size=kernel_size, strides=stride)(x)\n",
        "  return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLqVXU4V1Tpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def residual_block(x, num_filters):\n",
        "  input = x\n",
        "  x = conv_layer(x, num_filters, 3, 1)\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "\n",
        "  x = conv_layer(x, num_filters, 3, 1)\n",
        "  x = InstanceNormalization()(x)\n",
        "\n",
        "  x = Concatenate(axis=-1)([input, x])\n",
        "  return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niMpdkan5zun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deconv_layer(x, num_filters, kernel_size, stride, upsample_size):\n",
        "  reflection_size = kernel_size // 2\n",
        "  reflection_padding = (reflection_size, reflection_size)\n",
        "  x = UpSampling2D(size=upsample_size)(x)\n",
        "  x = ReflectionPadding2D(reflection_padding)(x)\n",
        "  x = Conv2D(filters=num_filters, kernel_size=kernel_size, strides=stride)(x)\n",
        "  return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh4WqtQsyeSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_net(input):\n",
        "  x = conv_layer(input, 32, 9, 1) #conv1\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = conv_layer(x, 64, 3, 2) # conv2\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = conv_layer(x, 128, 3, 2) # conv3\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = residual_block(x, 128) # res1\n",
        "  x = residual_block(x, 128) # res2\n",
        "  x = residual_block(x, 128) # res3\n",
        "  x = residual_block(x, 128) # res4\n",
        "  x = residual_block(x, 128) # res5\n",
        "  x = deconv_layer(x, 64, 3, 1, 2) # deconv1\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = deconv_layer(x, 32, 3, 1, 2) # deconv2\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = conv_layer(x, 3, 9, 1) # deconv3? apparently.\n",
        "\n",
        "  model = Model(input=input, output=x)\n",
        "  return model\n",
        "\n",
        "def style_model(net):\n",
        "  input_img = Input(shape=img_shape)\n",
        "  gen_img = net(input_img)\n",
        "\n",
        "  gen_features = extractor(gen_img)  \n",
        "  gen_style_features = gen_features[:num_style_layers]\n",
        "  gen_gram_style_features = [Lambda(gram_matrix)(gen_style_feature) for gen_style_feature in gen_style_features]\n",
        "  gen_content_features = gen_features[num_style_layers:]\n",
        "  \n",
        "  gen_features = gen_gram_style_features + gen_content_features\n",
        "\n",
        "  model = Model(input=input_img, output=gen_features)\n",
        "\n",
        "  # losses = [get_style_loss for i in range(num_style_layers)] + [get_content_loss for i in range(num_content_layers)]\n",
        "  losses = ['mean_squared_error' for i in range(len(gen_features))]\n",
        "\n",
        "  weight_per_style_layer = style_weight / num_style_layers\n",
        "  weight_per_content_layer = content_weight / num_content_layers\n",
        "\n",
        "  loss_weights = [ weight_per_style_layer for i in range(num_style_layers) ] + [ weight_per_content_layer for i in range(num_content_layers) ]\n",
        "\n",
        "  model.compile(loss=losses, loss_weights=loss_weights, optimizer=Adam())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdMo8CDhfKn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(img_path, img_type='normal'):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img, (img_shape[0], img_shape[1]))\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  return img\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JazHYuVDjH6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_extractor(layer_names, model):\n",
        "  outputs = [model.get_layer(name).output for name in layer_names]\n",
        "  model = Model(inputs=[vgg.input], outputs=outputs)\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2_bnG3gl2kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_imgs(imgs):\n",
        "  imgs = imgs * 255.\n",
        "  imgs = preprocess_input(imgs)\n",
        "  return imgs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl4SkGo6r3ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gram_matrix(tensor):\n",
        "  temp = tensor\n",
        "  batch_size, height, width, channels = temp.shape\n",
        "  fun = tf.reshape(temp, [channels, height * width])\n",
        "  result = tf.matmul(fun, fun, transpose_a=True)\n",
        "  gram = tf.expand_dims(result, axis=0)\n",
        "  return gram"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z0lLMsm8R8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_style_loss(gen_style, target_style):\n",
        "#   # gen_style = gram_matrix(gen_style)\n",
        "#   return tf.keras.losses.MeanAbsoluteError()(target_style, gen_style)\n",
        "\n",
        "# def get_content_loss(gen_content, target_content):\n",
        "#   return tf.keras.losses.MeanAbsoluteError()(target_content, gen_content)\n",
        "\n",
        "# def get_total_loss(gen_features, target_features):\n",
        "#   target_style_features = target_features[:num_style_layers]\n",
        "#   target_content_features = target_features[num_style_layers:]\n",
        "\n",
        "#   gen_style_features = gen_features[:num_style_layers]  \n",
        "\n",
        "#   total_style_loss = sum([get_style_loss(gen_feature, target_feature) for gen_feature, target_feature in zip(gen_style_features, target_style_features)])\n",
        "\n",
        "#   gen_content_features = gen_features[num_style_layers:]\n",
        "#   total_content_loss = sum([get_content_loss(gen_feature, target_feature) for gen_feature, target_feature in zip(gen_content_features, target_content_features)])\n",
        "\n",
        "#   total_loss = style_weight * total_style_loss + content_weight * total_content_loss\n",
        "\n",
        "#   return total_loss, total_style_loss, total_content_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E49FGxF5Goh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "14f51253-a7b0-4b06-fba4-14a55a03cb27"
      },
      "source": [
        "img_shape = (128, 128, 3)\n",
        "project_path = '/content/drive/My Drive/hairy_gan/'\n",
        "style_img_path = os.path.join(project_path, 'style.jpg')\n",
        "input_img_path = os.path.join(project_path, 'content.jpg')\n",
        "input_img = load_image(input_img_path)\n",
        "input_img = tf.expand_dims(input_img, axis=0)\n",
        "style_img = load_image(style_img_path)\n",
        "style_img = tf.expand_dims(style_img, axis=0)\n",
        "\n",
        "vgg = VGG19(include_top=False, weights='imagenet')\n",
        "vgg.trainable = False\n",
        "\n",
        "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1','block5_conv1']\n",
        "content_layers = ['block4_conv2']\n",
        "\n",
        "num_style_layers = len(style_layers)\n",
        "num_content_layers = len(content_layers)\n",
        "\n",
        "extractor = feature_extractor(style_layers + content_layers, vgg)\n",
        "\n",
        "input = Input(shape=img_shape)\n",
        "net = style_net(input)\n",
        "opt = tf.optimizers.Adam(learning_rate=0.02)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH7zK54K_e7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @tf.function()\n",
        "# def train_step(input_img):\n",
        "#   with tf.GradientTape() as tape: # auto calculates gradinets\n",
        "#     outputs = model(input_img)\n",
        "#     print(outputs)\n",
        "#     loss, _, _ = get_total_loss(outputs, input_features)\n",
        "\n",
        "#   grad = tape.gradient(loss, model.trainable_weights)\n",
        "\n",
        "#   opt.apply_gradients([(grad, model.trainable_weights)])\n",
        "\n",
        "#   image.assign(tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)) # clip pixels to be in range of [0, 1]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYB2RxEBsWa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100\n",
        "steps_per_epoch = 1\n",
        "content_weight = 10\n",
        "style_weight = 100\n",
        "\n",
        "processed_style_img = preprocess_imgs(style_img)\n",
        "style_features = extractor(processed_style_img)[:num_style_layers]\n",
        "gram_style_features = [gram_matrix(feature) for feature in style_features]\n",
        "\n",
        "processed_input_img = preprocess_imgs(input_img)\n",
        "input_features = extractor(processed_input_img)\n",
        "input_content_features = input_features[num_style_layers:]\n",
        "# input_features = gram_style_features + input_content_features"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJvSSanTbtmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47244821-c49a-4ada-ec24-e28c440438db"
      },
      "source": [
        "model = style_model(net)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoAcP-OCr7jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ae50913-81cf-4dfb-f73d-2eb0a94d812c"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    model.fit(processed_input_img, gram_style_features + input_content_features, steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3768744035692872657362623660032.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 371164899704832.0000 - lambda_8_loss: 58786295417143296.0000 - lambda_9_loss: 7051875511808403913572352.0000 - lambda_10_loss: 188430148458064818766040006656.0000 - model_1_loss: 832314736640.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 3818550570535175764731343405056.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 371376829497344.0000 - lambda_8_loss: 58829391118991360.0000 - lambda_9_loss: 7083303575563234258714624.0000 - lambda_10_loss: 190920441199141297473030455296.0000 - model_1_loss: 843721932800.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 3864008599204325050958645035008.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 371610167017472.0000 - lambda_8_loss: 58877559177216000.0000 - lambda_9_loss: 7115602095054042773323776.0000 - lambda_10_loss: 193193316187346457714382340096.0000 - model_1_loss: 852549238784.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 3902583306488043542322463375360.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 371784549400576.0000 - lambda_8_loss: 58936374459367424.0000 - lambda_9_loss: 7142896935214857572057088.0000 - lambda_10_loss: 195122025106280078212560060416.0000 - model_1_loss: 857472172032.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 3947183602288176249150310973440.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 371840719519744.0000 - lambda_8_loss: 59010479825092608.0000 - lambda_9_loss: 7175985205936321776844800.0000 - lambda_10_loss: 197352002117354850596790730752.0000 - model_1_loss: 862139383808.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 3993520217796730467130330316800.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 371907895492608.0000 - lambda_8_loss: 59102061412745216.0000 - lambda_9_loss: 7211594915988361155969024.0000 - lambda_10_loss: 199668795113850698538629988352.0000 - model_1_loss: 865942044672.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 4037892328848410912701452124160.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 372013491290112.0000 - lambda_8_loss: 59190284335972352.0000 - lambda_9_loss: 7244962193713940217724928.0000 - lambda_10_loss: 201887362887502857860024369152.0000 - model_1_loss: 869286805504.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 4085185809143190109673251405824.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 372151601332224.0000 - lambda_8_loss: 59273082715504640.0000 - lambda_9_loss: 7279756211801470252613632.0000 - lambda_10_loss: 204252021790669072525749649408.0000 - model_1_loss: 873460793344.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 4131673540379196156300109021184.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 372369168269312.0000 - lambda_8_loss: 59377033808969728.0000 - lambda_9_loss: 7316116473753008689119232.0000 - lambda_10_loss: 206576370573537511899930820608.0000 - model_1_loss: 878596718592.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 4177492131174045505678766768128.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 372545933017088.0000 - lambda_8_loss: 59478751519440896.0000 - lambda_9_loss: 7352048425365585681973248.0000 - lambda_10_loss: 208867266112241302707418169344.0000 - model_1_loss: 883097796608.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 4223811519489670215193046548480.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 372676426203136.0000 - lambda_8_loss: 59569237890433024.0000 - lambda_9_loss: 7387299576829692331687936.0000 - lambda_10_loss: 211183190193304302634538106880.0000 - model_1_loss: 888198463488.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 4267232508152768851260968271872.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 372779975180288.0000 - lambda_8_loss: 59647135712280576.0000 - lambda_9_loss: 7418727064123770373406720.0000 - lambda_10_loss: 213354194291740998889340141568.0000 - model_1_loss: 893563174912.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 4309836262961807998006788620288.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 372877786349568.0000 - lambda_8_loss: 59727790903132160.0000 - lambda_9_loss: 7449619595839710838128640.0000 - lambda_10_loss: 215484378254299769930914988032.0000 - model_1_loss: 898994864128.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 4350527497124216801398223798272.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 373003145707520.0000 - lambda_8_loss: 59802875521400832.0000 - lambda_9_loss: 7478611536455306915610624.0000 - lambda_10_loss: 217518887071915601960460353536.0000 - model_1_loss: 904335261696.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 4394177879461587313352046018560.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 373131424301056.0000 - lambda_8_loss: 59870869148663808.0000 - lambda_9_loss: 7508543108097157573378048.0000 - lambda_10_loss: 219701394855104568671002951680.0000 - model_1_loss: 910263189504.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 4430779922039149633560037556224.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 373257085648896.0000 - lambda_8_loss: 59937260753125376.0000 - lambda_9_loss: 7533344179043507762102272.0000 - lambda_10_loss: 221531462982944008019956989952.0000 - model_1_loss: 915527565312.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 4477697426404028680858503217152.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 373371774697472.0000 - lambda_8_loss: 60006487036002304.0000 - lambda_9_loss: 7564565869849013481635840.0000 - lambda_10_loss: 223877307978042470019150905344.0000 - model_1_loss: 922541359104.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 4527643289947042374239607848960.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 373480893710336.0000 - lambda_8_loss: 60080991833686016.0000 - lambda_9_loss: 7598278447565222294061056.0000 - lambda_10_loss: 226374570932047664322476769280.0000 - model_1_loss: 930285420544.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 4588377909735751922033084071936.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 373583637381120.0000 - lambda_8_loss: 60160667771994112.0000 - lambda_9_loss: 7639114350797644510527488.0000 - lambda_10_loss: 229411260364658092459272699904.0000 - model_1_loss: 939410063360.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 4653075690592613127918540816384.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 373720371691520.0000 - lambda_8_loss: 60245931462754304.0000 - lambda_9_loss: 7682117746458727599308800.0000 - lambda_10_loss: 232646100294889730909235314688.0000 - model_1_loss: 948939194368.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 4726013207604512742601501179904.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 373835832492032.0000 - lambda_8_loss: 60339011993993216.0000 - lambda_9_loss: 7730922066670240038649856.0000 - lambda_10_loss: 236292938366552848686221623296.0000 - model_1_loss: 959366758400.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 4797407530807674283142949109760.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 373969479794688.0000 - lambda_8_loss: 60433063187841024.0000 - lambda_9_loss: 7778153801949468738715648.0000 - lambda_10_loss: 239862594080419944981835284480.0000 - model_1_loss: 969187786752.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 4873672616138063164629288222720.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 374125507903488.0000 - lambda_8_loss: 60526513086267392.0000 - lambda_9_loss: 7827424478909594647658496.0000 - lambda_10_loss: 243675810568007526098990530560.0000 - model_1_loss: 979327713280.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 4947230009863970180421579177984.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 374300058058752.0000 - lambda_8_loss: 60624416865779712.0000 - lambda_9_loss: 7875190593306208621297664.0000 - lambda_10_loss: 247353627363798268748578684928.0000 - model_1_loss: 989013803008.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 5021672035058380201112461377536.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 374440349138944.0000 - lambda_8_loss: 60716157367222272.0000 - lambda_9_loss: 7922029182352366386544640.0000 - lambda_10_loss: 251075683288800534234528743424.0000 - model_1_loss: 998877954048.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 5097297296398738040108087246848.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 374571479859200.0000 - lambda_8_loss: 60803594311434240.0000 - lambda_9_loss: 7968526506633160525086720.0000 - lambda_10_loss: 254856882131634259157135130624.0000 - model_1_loss: 1008866492416.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 5177878851368060955062714761216.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 374689994113024.0000 - lambda_8_loss: 60890614643818496.0000 - lambda_9_loss: 8017446118995133649125376.0000 - lambda_10_loss: 258885929656954914539137138688.0000 - model_1_loss: 1019225243648.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 5262077512389670840508063154176.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 374791966031872.0000 - lambda_8_loss: 60974319261450240.0000 - lambda_9_loss: 8067813224306140669542400.0000 - lambda_10_loss: 263095806039637614375661993984.0000 - model_1_loss: 1029829820416.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 5343479927990512088672316162048.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 374879710871552.0000 - lambda_8_loss: 61052637990092800.0000 - lambda_9_loss: 8116159258219571887210496.0000 - lambda_10_loss: 267165881484961441235280592896.0000 - model_1_loss: 1039276638208.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 5423962351042626604034617769984.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 374915479896064.0000 - lambda_8_loss: 61129608099004416.0000 - lambda_9_loss: 8163318359444010355916800.0000 - lambda_10_loss: 271189961080742117750517792768.0000 - model_1_loss: 1047936106496.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 5490909036155425923842321678336.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 374976079200256.0000 - lambda_8_loss: 61212015636512768.0000 - lambda_9_loss: 8203477497753228353208320.0000 - lambda_10_loss: 274537250001663848192308936704.0000 - model_1_loss: 1055650545664.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 5557648994953071142061150830592.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375019431526400.0000 - lambda_8_loss: 61289217673658368.0000 - lambda_9_loss: 8242632441431933786783744.0000 - lambda_10_loss: 277874206384721059850372513792.0000 - model_1_loss: 1063485964288.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 5630509745175425227791517351936.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375080030830592.0000 - lambda_8_loss: 61373158514491392.0000 - lambda_9_loss: 8285775917055826607472640.0000 - lambda_10_loss: 281517191005334155996864446464.0000 - model_1_loss: 1072096542720.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 5699068532868680655603691945984.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375174083903488.0000 - lambda_8_loss: 61458559644205056.0000 - lambda_9_loss: 8326489610608760498159616.0000 - lambda_10_loss: 284945100166851437021743808512.0000 - model_1_loss: 1080003264512.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 5775490778555619438882742861824.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375285853716480.0000 - lambda_8_loss: 61554122666541056.0000 - lambda_9_loss: 8372219089167486476615680.0000 - lambda_10_loss: 288766174672266513228534644736.0000 - model_1_loss: 1088554532864.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 5851703880075764891314569609216.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375396046471168.0000 - lambda_8_loss: 61644707821780992.0000 - lambda_9_loss: 8416588696811528679063552.0000 - lambda_10_loss: 292576765524089618822951075840.0000 - model_1_loss: 1097671049216.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 5927181350234674841893587648512.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375504326623232.0000 - lambda_8_loss: 61737036733743104.0000 - lambda_9_loss: 8460623380758482592464896.0000 - lambda_10_loss: 296350597475210067099024097280.0000 - model_1_loss: 1106065752064.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 6000146068077515785732978900992.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375614083170304.0000 - lambda_8_loss: 61832067180134400.0000 - lambda_9_loss: 8503608906136244275118080.0000 - lambda_10_loss: 299998814477886182812412805120.0000 - model_1_loss: 1113533054976.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 6077491328627730338386917982208.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375711122587648.0000 - lambda_8_loss: 61911455355633664.0000 - lambda_9_loss: 8545880773102654319493120.0000 - lambda_10_loss: 303866035948571861192231878656.0000 - model_1_loss: 1121148207104.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 6163630920052731510972257140736.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375822623965184.0000 - lambda_8_loss: 61993235827916800.0000 - lambda_9_loss: 8592826583848740521508864.0000 - lambda_10_loss: 308172947517744566498607759360.0000 - model_1_loss: 1129353183232.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 6255327943470501133873720590336.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 375902147969024.0000 - lambda_8_loss: 62074629753143296.0000 - lambda_9_loss: 8642026356136333109362688.0000 - lambda_10_loss: 312757760909701184686519222272.0000 - model_1_loss: 1138279186432.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 6345259330728723590865525669888.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376019521372160.0000 - lambda_8_loss: 62154400180731904.0000 - lambda_9_loss: 8689651237648632744247296.0000 - lambda_10_loss: 317254284937894071987515424768.0000 - model_1_loss: 1147050524672.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 6449573308462901291148810125312.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376136794112000.0000 - lambda_8_loss: 62234140543549440.0000 - lambda_9_loss: 8743980357710221194297344.0000 - lambda_10_loss: 322469930934098348861653254144.0000 - model_1_loss: 1157274796032.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 6549014710681122228543441338368.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376263025885184.0000 - lambda_8_loss: 62305638864125952.0000 - lambda_9_loss: 8793828648344155133575168.0000 - lambda_10_loss: 327441940598718414999926079488.0000 - model_1_loss: 1166904131584.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 6652175977646297379908643454976.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376383486296064.0000 - lambda_8_loss: 62375483622293504.0000 - lambda_9_loss: 8844275305238980026433536.0000 - lambda_10_loss: 332599973723831682202456817664.0000 - model_1_loss: 1176711462912.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 6758313619979363748301972176896.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376503678271488.0000 - lambda_8_loss: 62447179511365632.0000 - lambda_9_loss: 8895250576643667158630400.0000 - lambda_10_loss: 337906818061553137664961544192.0000 - model_1_loss: 1185909440512.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 6870159810032650395658263461888.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376603032944640.0000 - lambda_8_loss: 62525914851835904.0000 - lambda_9_loss: 8949330089199508226310144.0000 - lambda_10_loss: 343499044450567371527020347392.0000 - model_1_loss: 1194908975104.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 6989514638351563504818654806016.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376683093819392.0000 - lambda_8_loss: 62601231398338560.0000 - lambda_9_loss: 9005714868303810684518400.0000 - lambda_10_loss: 349466755643367536619310546944.0000 - model_1_loss: 1205437857792.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 7113821831290527942393230000128.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376776240922624.0000 - lambda_8_loss: 62675014641516544.0000 - lambda_9_loss: 9063005267249981821026304.0000 - lambda_10_loss: 355682032176665659992283545600.0000 - model_1_loss: 1216618168320.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 7239292010867961653233872535552.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376844524191744.0000 - lambda_8_loss: 62755940415307776.0000 - lambda_9_loss: 9121243367672939785748480.0000 - lambda_10_loss: 361955488265032737394289278976.0000 - model_1_loss: 1226621452288.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 7373149113318971853974039166976.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376903378665472.0000 - lambda_8_loss: 62834727295385600.0000 - lambda_9_loss: 9181812675378212795056128.0000 - lambda_10_loss: 368648290497078639291271217152.0000 - model_1_loss: 1238056435712.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 7516466664771376335320868978688.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 376975386476544.0000 - lambda_8_loss: 62914514902843392.0000 - lambda_9_loss: 9245722573143084143476736.0000 - lambda_10_loss: 375814084956048764852856946688.0000 - model_1_loss: 1250394112000.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 7643426845421485076619336876032.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377042696667136.0000 - lambda_8_loss: 62996664742313984.0000 - lambda_9_loss: 9303101747045110007201792.0000 - lambda_10_loss: 382162041098049593777753948160.0000 - model_1_loss: 1261814415360.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 7791066911141921664580328620032.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377123697065984.0000 - lambda_8_loss: 63075696435527680.0000 - lambda_9_loss: 9367694174340708609032192.0000 - lambda_10_loss: 389543968826207697261480116224.0000 - model_1_loss: 1274839826432.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 7940874580856927282651568537600.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377246841831424.0000 - lambda_8_loss: 63168188556247040.0000 - lambda_9_loss: 9433151869225514649518080.0000 - lambda_10_loss: 397034284309880624842151034880.0000 - model_1_loss: 1287995916288.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 8089710878675872546180932042752.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377344149684224.0000 - lambda_8_loss: 63254835226476544.0000 - lambda_9_loss: 9496653632777755174109184.0000 - lambda_10_loss: 404476053866109652470025158656.0000 - model_1_loss: 1300927741952.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 8244686101806820896659453509632.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377452933152768.0000 - lambda_8_loss: 63347065354190848.0000 - lambda_9_loss: 9562475074397264674816000.0000 - lambda_10_loss: 412224739464793344079627812864.0000 - model_1_loss: 1313717354496.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 8402920588947450287392982827008.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377565676044288.0000 - lambda_8_loss: 63435906752708608.0000 - lambda_9_loss: 9627861864609537394212864.0000 - lambda_10_loss: 420136403375533832884845543424.0000 - model_1_loss: 1325534806016.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 8526927363820240489617643536384.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377665433370624.0000 - lambda_8_loss: 63496109309296640.0000 - lambda_9_loss: 9676190028239647205752832.0000 - lambda_10_loss: 426336681672882362264619843584.0000 - model_1_loss: 1335159029760.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 8655092843512505016203293491200.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377764754489344.0000 - lambda_8_loss: 63556045577912320.0000 - lambda_9_loss: 9725078511720995944923136.0000 - lambda_10_loss: 432744932990136470819605315584.0000 - model_1_loss: 1345540587520.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 8791508637460729579591725744128.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377886926176256.0000 - lambda_8_loss: 63620753555193856.0000 - lambda_9_loss: 9777139835183022726971392.0000 - lambda_10_loss: 439565654685470345666135851008.0000 - model_1_loss: 1356524814336.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 8939502313983403446586319044608.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 377998662434816.0000 - lambda_8_loss: 63680616809365504.0000 - lambda_9_loss: 9831720292132615469662208.0000 - lambda_10_loss: 446965300732672176058703806464.0000 - model_1_loss: 1367833575424.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 9090790917827436985396574027776.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 378080333922304.0000 - lambda_8_loss: 63738173666099200.0000 - lambda_9_loss: 9886455240563825529847808.0000 - lambda_10_loss: 454529662922796499676325478400.0000 - model_1_loss: 1379233562624.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 9236525716456160917778228838400.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 378165629288448.0000 - lambda_8_loss: 63788832805355520.0000 - lambda_9_loss: 9937654178740406390358016.0000 - lambda_10_loss: 461816349963728088155381825536.0000 - model_1_loss: 1389940047872.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 9378725011525421867138455437312.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 378244985520128.0000 - lambda_8_loss: 63836554186981376.0000 - lambda_9_loss: 9986734047191519866126336.0000 - lambda_10_loss: 468926269382472900074799104000.0000 - model_1_loss: 1400472469504.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 9528657805062757599329277444096.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 378351755722752.0000 - lambda_8_loss: 63880951263920128.0000 - lambda_9_loss: 10036823874880668939845632.0000 - lambda_10_loss: 476422856168835078544313810944.0000 - model_1_loss: 1412728094720.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 9697561062561486092529588764672.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 378451479494656.0000 - lambda_8_loss: 63919498595401728.0000 - lambda_9_loss: 10091840136159003070693376.0000 - lambda_10_loss: 484867958597480522472870641664.0000 - model_1_loss: 1425905942528.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 9867390961700949198992312369152.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 378565698781184.0000 - lambda_8_loss: 63961649404444672.0000 - lambda_9_loss: 10147269143335986452758528.0000 - lambda_10_loss: 493359377996589951881683402752.0000 - model_1_loss: 1439052201984.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 10056595106025556352608877150208.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 378679616077824.0000 - lambda_8_loss: 64021151881363456.0000 - lambda_9_loss: 10210267080190713785221120.0000 - lambda_10_loss: 502819562545461191788214616064.0000 - model_1_loss: 1452911362048.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 10265044744935518595372176900096.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 378801854873600.0000 - lambda_8_loss: 64085176958844928.0000 - lambda_9_loss: 10279593403184228100734976.0000 - lambda_10_loss: 513241976488881950603488526336.0000 - model_1_loss: 1468308389888.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 10464914032840766007567999565824.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 378910235688960.0000 - lambda_8_loss: 64161369678675968.0000 - lambda_9_loss: 10347034699517710221443072.0000 - lambda_10_loss: 523235372882066967890388582400.0000 - model_1_loss: 1482182623232.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 10661502296071579316183669669888.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379026971557888.0000 - lambda_8_loss: 64235934605901824.0000 - lambda_9_loss: 10411749336492797149052928.0000 - lambda_10_loss: 533064657595239299266822275072.0000 - model_1_loss: 1496210735104.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 10888398329600131378209223606272.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379151391391744.0000 - lambda_8_loss: 64304976205185024.0000 - lambda_9_loss: 10483808083452229691899904.0000 - lambda_10_loss: 544409406381162294228073578496.0000 - model_1_loss: 1512341897216.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 11127020943578945343229427449856.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379256584536064.0000 - lambda_8_loss: 64372720724344832.0000 - lambda_9_loss: 10556696933894979164569600.0000 - lambda_10_loss: 556340484189598384339057377280.0000 - model_1_loss: 1529760710656.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 11378022957950613110998622535680.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379347617710080.0000 - lambda_8_loss: 64431707805188096.0000 - lambda_9_loss: 10630095375642764863602688.0000 - lambda_10_loss: 568890532017677164587490738176.0000 - model_1_loss: 1548337283072.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 11645550988276412859586051047424.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379416135860224.0000 - lambda_8_loss: 64501685707341824.0000 - lambda_9_loss: 10708862972837504649003008.0000 - lambda_10_loss: 582266842864530680919674060800.0000 - model_1_loss: 1568032817152.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 11931131907866517865639366885376.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379496834269184.0000 - lambda_8_loss: 64575121058168832.0000 - lambda_9_loss: 10792129269743220351303680.0000 - lambda_10_loss: 596545767951453969759422382080.0000 - model_1_loss: 1587984990208.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 12219932196914256629184925270016.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379583304040448.0000 - lambda_8_loss: 64636831148277760.0000 - lambda_9_loss: 10873062053523611795324928.0000 - lambda_10_loss: 610985744624909044979538591744.0000 - model_1_loss: 1607743307776.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 12525674372398074805984816005120.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379689570926592.0000 - lambda_8_loss: 64706031661350912.0000 - lambda_9_loss: 10958227212147414974595072.0000 - lambda_10_loss: 626272762729663482722345025536.0000 - model_1_loss: 1628037447680.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 12848536146413455746527720898560.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379778725052416.0000 - lambda_8_loss: 64782134186868736.0000 - lambda_9_loss: 11047689309218887872544768.0000 - lambda_10_loss: 642415775872568803835166851072.0000 - model_1_loss: 1648001548288.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 13195789207765381445299497598976.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379837713743872.0000 - lambda_8_loss: 64857871640166400.0000 - lambda_9_loss: 11142797262898420500135936.0000 - lambda_10_loss: 659778368493874108042296950784.0000 - model_1_loss: 1668085972992.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 13576460605548914338347677122560.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 379919586557952.0000 - lambda_8_loss: 64945823980453888.0000 - lambda_9_loss: 11246904921842914175221760.0000 - lambda_10_loss: 678811772155750555683194404864.0000 - model_1_loss: 1688800591872.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 13935309683362583560163235463168.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380035114467328.0000 - lambda_8_loss: 65024585090727936.0000 - lambda_9_loss: 11340974093246796033687552.0000 - lambda_10_loss: 696754120265424800493919535104.0000 - model_1_loss: 1708753944576.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 14299805653679672714853846351872.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380147253379072.0000 - lambda_8_loss: 65102474322640896.0000 - lambda_9_loss: 11433712793234361590743040.0000 - lambda_10_loss: 714978903669706513045585395712.0000 - model_1_loss: 1727102189568.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 14646242690103358538932696383488.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380238588542976.0000 - lambda_8_loss: 65160761323814912.0000 - lambda_9_loss: 11517185463089401918652416.0000 - lambda_10_loss: 732300619486736097603745742848.0000 - model_1_loss: 1744546824192.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 14987923812352680411838252318720.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380354015789056.0000 - lambda_8_loss: 65205261479968768.0000 - lambda_9_loss: 11595618713047805718429696.0000 - lambda_10_loss: 749384630264483955700429488128.0000 - model_1_loss: 1762214936576.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 15320702404866360155501271973888.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380479542919168.0000 - lambda_8_loss: 65260164046913536.0000 - lambda_9_loss: 11673016639495072569622528.0000 - lambda_10_loss: 766023454109158726603527684096.0000 - model_1_loss: 1779975192576.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 15637176214850897395485029433344.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380606982651904.0000 - lambda_8_loss: 65312201870671872.0000 - lambda_9_loss: 11745078845219018933010432.0000 - lambda_10_loss: 781847084162094607871256821760.0000 - model_1_loss: 1796643225600.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 15934295122463404422381741015040.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380725027143680.0000 - lambda_8_loss: 65367078667812864.0000 - lambda_9_loss: 11811583969290760293974016.0000 - lambda_10_loss: 796702969096428978484633665536.0000 - model_1_loss: 1811491586048.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 16266204497312781247668146929664.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380830354505728.0000 - lambda_8_loss: 65426276202053632.0000 - lambda_9_loss: 11886113427034565309890560.0000 - lambda_10_loss: 813298347169461348651765858304.0000 - model_1_loss: 1827447635968.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 16621929710808566267696264511488.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380877028720640.0000 - lambda_8_loss: 65475092800339968.0000 - lambda_9_loss: 11962482947499722853580800.0000 - lambda_10_loss: 831084517174814128555983634432.0000 - model_1_loss: 1843971096576.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 16992079827183993043036976185344.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 380970645585920.0000 - lambda_8_loss: 65530381914341376.0000 - lambda_9_loss: 12041096053212845321486336.0000 - lambda_10_loss: 849591962547294486591560482816.0000 - model_1_loss: 1860993679360.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 17382284813981006901756888612864.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 381055336972288.0000 - lambda_8_loss: 65586048985464832.0000 - lambda_9_loss: 12123471141795499931074560.0000 - lambda_10_loss: 869102136329281453613232685056.0000 - model_1_loss: 1879090921472.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 17777828417197438962912303513600.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 381130465345536.0000 - lambda_8_loss: 65636811203936256.0000 - lambda_9_loss: 12204631051112298923950080.0000 - lambda_10_loss: 888879180485948350025221275648.0000 - model_1_loss: 1897308880896.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 18220250536921067499575299801088.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 381182978031616.0000 - lambda_8_loss: 65679485998989312.0000 - lambda_9_loss: 12294850617612298520363008.0000 - lambda_10_loss: 911000180691120560578318303232.0000 - model_1_loss: 1916838608896.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 18604674440448684201581767294976.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 381242067386368.0000 - lambda_8_loss: 65723376269787136.0000 - lambda_9_loss: 12371612131389022392025088.0000 - lambda_10_loss: 930221345644355905312912310272.0000 - model_1_loss: 1932600934400.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 19025187197543436813711563554816.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 381307733409792.0000 - lambda_8_loss: 65772270177484800.0000 - lambda_9_loss: 12455807683027451212988416.0000 - lambda_10_loss: 951246907941229810005078704128.0000 - model_1_loss: 1949245898752.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 19478200716372709116574160650240.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 381368198496256.0000 - lambda_8_loss: 65822413920665600.0000 - lambda_9_loss: 12544559580452086293200896.0000 - lambda_10_loss: 973897493213256954051020455936.0000 - model_1_loss: 1965526089728.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 19939847174479849486373334548480.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 381408296042496.0000 - lambda_8_loss: 65863692851347456.0000 - lambda_9_loss: 12632869908940456951021568.0000 - lambda_10_loss: 996979740560750246626655731712.0000 - model_1_loss: 1982972821504.0000\n",
            "Epoch 1/1\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 20348951298614898842981428625408.0000 - lambda_6_loss: 17122988032.0000 - lambda_7_loss: 381449064677376.0000 - lambda_8_loss: 65905336854249472.0000 - lambda_9_loss: 12708002344631171347906560.0000 - lambda_10_loss: 1017434840986493498177007648768.0000 - model_1_loss: 1998395277312.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "forSCak5FZBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}