{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "api_rnd.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwKP6D/cCYg1YcltqJkqeD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/hairy_gan/blob/master/api_rnd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo3Euyfe3PZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "9ab4d5b0-ce04-443d-c8db-10677b87a734"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoYRBnlRzACO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3da1c82-81c2-4f77-85a0-ae9f29410fcd"
      },
      "source": [
        "import scipy\n",
        "from keras.models import Model, Sequential\n",
        "# from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Embedding\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model, save_model\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.backend import set_session, clear_session\n",
        "# tf.compat.v1.disable_v2_behavior()\n",
        "\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "\n",
        "import requests\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "import json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAB2JS5521aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/layers/normalization/instancenormalization.py\n",
        "\n",
        "from keras.layers import Layer, InputSpec\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class InstanceNormalization(Layer):\n",
        "    \"\"\"Instance normalization layer.\n",
        "    Normalize the activations of the previous layer at each step,\n",
        "    i.e. applies a transformation that maintains the mean activation\n",
        "    close to 0 and the activation standard deviation close to 1.\n",
        "    # Arguments\n",
        "        axis: Integer, the axis that should be normalized\n",
        "            (typically the features axis).\n",
        "            For instance, after a `Conv2D` layer with\n",
        "            `data_format=\"channels_first\"`,\n",
        "            set `axis=1` in `InstanceNormalization`.\n",
        "            Setting `axis=None` will normalize all values in each\n",
        "            instance of the batch.\n",
        "            Axis 0 is the batch dimension. `axis` cannot be set to 0 to avoid errors.\n",
        "        epsilon: Small float added to variance to avoid dividing by zero.\n",
        "        center: If True, add offset of `beta` to normalized tensor.\n",
        "            If False, `beta` is ignored.\n",
        "        scale: If True, multiply by `gamma`.\n",
        "            If False, `gamma` is not used.\n",
        "            When the next layer is linear (also e.g. `nn.relu`),\n",
        "            this can be disabled since the scaling\n",
        "            will be done by the next layer.\n",
        "        beta_initializer: Initializer for the beta weight.\n",
        "        gamma_initializer: Initializer for the gamma weight.\n",
        "        beta_regularizer: Optional regularizer for the beta weight.\n",
        "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
        "        beta_constraint: Optional constraint for the beta weight.\n",
        "        gamma_constraint: Optional constraint for the gamma weight.\n",
        "    # Input shape\n",
        "        Arbitrary. Use the keyword argument `input_shape`\n",
        "        (tuple of integers, does not include the samples axis)\n",
        "        when using this layer as the first layer in a Sequential model.\n",
        "    # Output shape\n",
        "        Same shape as input.\n",
        "    # References\n",
        "        - [Layer Normalization](https://arxiv.org/abs/1607.06450)\n",
        "        - [Instance Normalization: The Missing Ingredient for Fast Stylization](\n",
        "        https://arxiv.org/abs/1607.08022)\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 axis=None,\n",
        "                 epsilon=1e-3,\n",
        "                 center=True,\n",
        "                 scale=True,\n",
        "                 beta_initializer='zeros',\n",
        "                 gamma_initializer='ones',\n",
        "                 beta_regularizer=None,\n",
        "                 gamma_regularizer=None,\n",
        "                 beta_constraint=None,\n",
        "                 gamma_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(InstanceNormalization, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.axis = axis\n",
        "        self.epsilon = epsilon\n",
        "        self.center = center\n",
        "        self.scale = scale\n",
        "        self.beta_initializer = initializers.get(beta_initializer)\n",
        "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
        "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
        "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
        "        self.beta_constraint = constraints.get(beta_constraint)\n",
        "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        ndim = len(input_shape)\n",
        "        if self.axis == 0:\n",
        "            raise ValueError('Axis cannot be zero')\n",
        "\n",
        "        if (self.axis is not None) and (ndim == 2):\n",
        "            raise ValueError('Cannot specify axis for rank 1 tensor')\n",
        "\n",
        "        self.input_spec = InputSpec(ndim=ndim)\n",
        "\n",
        "        if self.axis is None:\n",
        "            shape = (1,)\n",
        "        else:\n",
        "            shape = (input_shape[self.axis],)\n",
        "\n",
        "        if self.scale:\n",
        "            self.gamma = self.add_weight(shape=shape,\n",
        "                                         name='gamma',\n",
        "                                         initializer=self.gamma_initializer,\n",
        "                                         regularizer=self.gamma_regularizer,\n",
        "                                         constraint=self.gamma_constraint)\n",
        "        else:\n",
        "            self.gamma = None\n",
        "        if self.center:\n",
        "            self.beta = self.add_weight(shape=shape,\n",
        "                                        name='beta',\n",
        "                                        initializer=self.beta_initializer,\n",
        "                                        regularizer=self.beta_regularizer,\n",
        "                                        constraint=self.beta_constraint)\n",
        "        else:\n",
        "            self.beta = None\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_shape = K.int_shape(inputs)\n",
        "        reduction_axes = list(range(0, len(input_shape)))\n",
        "\n",
        "        if self.axis is not None:\n",
        "            del reduction_axes[self.axis]\n",
        "\n",
        "        del reduction_axes[0]\n",
        "\n",
        "        mean = K.mean(inputs, reduction_axes, keepdims=True)\n",
        "        stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n",
        "        normed = (inputs - mean) / stddev\n",
        "\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        if self.axis is not None:\n",
        "            broadcast_shape[self.axis] = input_shape[self.axis]\n",
        "\n",
        "        if self.scale:\n",
        "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
        "            normed = normed * broadcast_gamma\n",
        "        if self.center:\n",
        "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
        "            normed = normed + broadcast_beta\n",
        "        return normed\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'axis': self.axis,\n",
        "            'epsilon': self.epsilon,\n",
        "            'center': self.center,\n",
        "            'scale': self.scale,\n",
        "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
        "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
        "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
        "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
        "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
        "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
        "        }\n",
        "        base_config = super(InstanceNormalization, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8wlyQMU2mIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f4c25cbf-3e95-4f1c-ed20-20f99258b78f"
      },
      "source": [
        "project_path = '/content/drive/My Drive/hairy_gan'\n",
        "\n",
        "enc = load_model(os.path.join(project_path, 'glasses_only', 'enc.h5'), custom_objects={'InstanceNormalization': InstanceNormalization})\n",
        "dec = load_model(os.path.join(project_path, 'glasses_only', 'dec.h5'), custom_objects={'InstanceNormalization': InstanceNormalization})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGkFsc7N5HKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_imgs(img_paths, preprocess=True):\n",
        "  imgs = []\n",
        "  img_props = []\n",
        "\n",
        "  for img_path in img_paths:\n",
        "\n",
        "    if isinstance(img_path, str):\n",
        "      img = plt.imread(img_path) * 255.\n",
        "      img = img[:, :, :3]\n",
        "    else:\n",
        "      img = img_path\n",
        "\n",
        "    img_props.append(img.shape)\n",
        "\n",
        "    if preprocess:\n",
        "      img = cv2.resize(img, img_res)\n",
        "      img = img / 127.5 - 1.\n",
        "    imgs.append(img)\n",
        "\n",
        "  imgs = np.array(imgs)\n",
        "  return imgs, img_props"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD-bkosG7euq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(imgs, attrs):\n",
        "  imgs = np.array(imgs)\n",
        "  attrs = np.array(attrs)\n",
        "  encodings = enc.predict(imgs)\n",
        "  predictions = dec.predict([encodings, attrs])\n",
        "  return predictions"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv8I8z1S8GSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def post_process_imgs(imgs, img_props):\n",
        "  imgs = np.array([cv2.resize(img, (img_prop[1], img_prop[0])) for img, img_prop in zip(imgs, img_props)])\n",
        "  return (imgs + 1.) * 127.5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0TVBj1E6nVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model requirements\n",
        "img_res = enc.input_shape[1:-1]\n",
        "attr_size = 1\n",
        "\n",
        "# website link\n",
        "website_link = 'https://hairygan--garlandzhang.repl.co'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3woL3hdZTxv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMGUR_URL = 'https://api.imgur.com/3/'\n",
        "CLIENT_ID = '853e92d46b2081a'\n",
        "CLIENT_SECRET = '5c77e3cad7f64553ce00913309896c4482ed0c79'\n",
        "RAGIC_ID = 'WGhod3FVU0lmNHNjaXVyTmpXbUJhVjlKMUNxTGVZM2JJejk2K2FHRW5XT3I2dXB5bXY0UythaWVQbUd6MXUrS293TjZKT1VBYStBPQ=='\n",
        "DB_URL = 'https://na3.ragic.com/weewoowarrior/hairygan/2?v=3&api'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD2S7EIXjl5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while True:\n",
        "  # user inputs\n",
        "  attrs = [[1]] # give this person glasses\n",
        "\n",
        "  # user img\n",
        "  img_paths = [] # also acts as array for imgs\n",
        "  while True:\n",
        "    db_data_retrieval_res = requests.get(\n",
        "        url=DB_URL,\n",
        "        headers={\n",
        "          'Authorization': 'Basic ' + RAGIC_ID\n",
        "        }\n",
        "    )\n",
        "\n",
        "    retrieved_data = json.loads(db_data_retrieval_res.content)\n",
        "\n",
        "    entries = list(retrieved_data.items())\n",
        "    entries.sort()\n",
        "\n",
        "    if int(entries[-1][1]['processed']) == 0:\n",
        "      time.sleep(1)\n",
        "      entry_id = entries[-1][0]\n",
        "      img_url = entries[-1][1]['original_image_url'] # get last entry, value, image url (most recent)\n",
        "      img_paths = [img_url]\n",
        "      break\n",
        "\n",
        "    print('All processed')\n",
        "    time.sleep(1)\n",
        "\n",
        "  start_time = time.time()\n",
        "  imgs, img_props = load_imgs(img_paths, preprocess=True) # in truth we only deal with one image...\n",
        "  orig_imgs, _ = load_imgs(img_paths, preprocess=False)\n",
        "  predictions = get_predictions(imgs, attrs)\n",
        "  pred_imgs = post_process_imgs(predictions, img_props)\n",
        "  end_time = time.time()\n",
        "  time_diff = end_time - start_time\n",
        "\n",
        "\n",
        "  img_enc = base64.b64encode(pred_imgs[0].astype(np.uint8))\n",
        "  img_prop_enc = base64.b64encode(np.array(img_props[0][:-1], dtype=np.uint8))\n",
        "  x = requests.post(os.path.join(website_link, 'predictions'), data={'predictions': img_enc, 'img_props': img_prop_enc })\n",
        "\n",
        "  img = cv2.cvtColor(pred_imgs[0].astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
        "  cv2.imwrite('img.jpg', img) # use local save as hack\n",
        "  img_bytes = open('img.jpg', 'rb').read()\n",
        "\n",
        "  # upload to img db\n",
        "  print('Upload to image database')\n",
        "\n",
        "  res = requests.post(\n",
        "    url= IMGUR_URL + 'upload.json',\n",
        "    data={\n",
        "        'image': base64.b64encode(img_bytes),\n",
        "        'type': 'base64',\n",
        "    },\n",
        "    headers={\n",
        "        'Authorization': 'Client-ID ' + CLIENT_IDI,\n",
        "    }\n",
        "  )\n",
        "\n",
        "  data = json.loads(res.content.decode(\"utf-8\"))['data']\n",
        "  print(data)\n",
        "\n",
        "  # update database\n",
        "  print('Update database')\n",
        "\n",
        "  res = requests.post(\n",
        "    url=f'https://na3.ragic.com/weewoowarrior/hairygan/2/{entry_id}?v=3&api', \n",
        "    params={\n",
        "        '1000017': data['link'],\n",
        "        '1000018': 1,\n",
        "    },\n",
        "    headers={\n",
        "        'Authorization': 'Basic ' + RAGIC_ID\n",
        "    }\n",
        "  )\n",
        "\n",
        "  time.sleep(1)\n",
        "  print('Done')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qeZSICutnmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "6a479cd9-bbb7-40c0-de0f-7bc627777c0a"
      },
      "source": [
        "seg_model = load_model(os.path.join(project_path, 'g_IS.h5'), custom_objects={'InstanceNormalization': InstanceNormalization})"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrZFtjVChwp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs, img_props = load_imgs([os.path.join(project_path, 'wardell.png')], preprocess=False)\n",
        "imgs = np.array([cv2.resize(img, img_res) for img in imgs]) / 255."
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QqVBx7QwoX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = seg_model.predict(imgs) * 255."
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfnWWPkZxZ7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03cfe40c-c14b-425e-d0d6-29a7ffab12e9"
      },
      "source": [
        "cv2.imwrite('img.jpg', preds[0])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mu2WW0YzFOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}